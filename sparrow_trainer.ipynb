{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e49a65-15e0-46d2-afd2-d50c3ddc1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from typing import Dict, List, Tuple, Set, Optional\n",
    "# Add TensorBoard imports\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Add tqdm for progress bars\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Import the meta-agent for strategy selection\n",
    "from meta_agent import SparrowMetaController, LearningState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ab7f6c-ec62-4412-a708-6807b1404655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparrowCoresetSelector:\n",
    "    \"\"\"\n",
    "    SPARROW: Strategic Policy-based Active Re-weighting Workflow\n",
    "    This class implements the coreset selection algorithm described in the paper\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 full_dataset,\n",
    "                 budget: int, \n",
    "                 initial_samples: int = 1000,\n",
    "                 device=None):\n",
    "        \"\"\"\n",
    "        Initialize the SPARROW coreset selector\n",
    "        \n",
    "        Args:\n",
    "            full_dataset: The full dataset\n",
    "            budget: Maximum number of samples to select\n",
    "            initial_samples: Number of initial samples to randomly select\n",
    "            device: Device to use for computation\n",
    "        \"\"\"\n",
    "        self.full_dataset = full_dataset\n",
    "        self.budget = budget\n",
    "        self.initial_samples = initial_samples\n",
    "        \n",
    "        # Enhanced device selection logic with MPS support\n",
    "        if device is None:\n",
    "            # Try CUDA first\n",
    "            if torch.cuda.is_available():\n",
    "                self.device = torch.device(\"cuda\")\n",
    "            # Then try MPS (Apple Silicon)\n",
    "            elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "                self.device = torch.device(\"mps\")\n",
    "            # Fall back to CPU\n",
    "            else:\n",
    "                self.device = torch.device(\"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize strategy weights\n",
    "        self.strategies = [\"S_U\", \"S_D\", \"S_C\", \"S_B\"]  # Uncertainty, Diversity, Class Balance, Boundary\n",
    "        self.weights = {s: 0.25 for s in self.strategies}  # Equal initial weights\n",
    "        \n",
    "        # Temperature parameter for exploration vs exploitation\n",
    "        self.temperature = 0.5\n",
    "        \n",
    "        # Initialize the selected indices with random samples\n",
    "        print(f\"Initializing with {initial_samples} samples...\")\n",
    "        self.current_indices = self._initial_sampling(initial_samples)\n",
    "        \n",
    "        # Initialize meta_controller to None\n",
    "        self.meta_controller = None\n",
    "        \n",
    "        # Try to set up meta-controller if available\n",
    "        try:\n",
    "            # Check if the meta_agent module and SparrowMetaController class are available\n",
    "            from meta_agent import SparrowMetaController\n",
    "            \n",
    "            # Create meta-controller instance\n",
    "            self.meta_controller = SparrowMetaController(\n",
    "                strategies=self.strategies,\n",
    "                initial_temperature=0.5,\n",
    "                total_epochs=200  # Assuming 200 epochs\n",
    "            )\n",
    "            print(\"Meta-controller initialized successfully\")\n",
    "        except (ImportError, ModuleNotFoundError) as e:\n",
    "            print(f\"Meta-controller not available: {e}\")\n",
    "            print(\"Using basic strategy weighting\")\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.performance_history = []\n",
    "        self.weight_history = []\n",
    "        \n",
    "        # Current epoch tracking\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "        # Save initial weights\n",
    "        self._save_weights()\n",
    "    \n",
    "    def _initial_sampling(self, n_samples: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Perform initial sampling to select a diverse set of samples\n",
    "        \n",
    "        Args:\n",
    "            n_samples: Number of samples to select\n",
    "            \n",
    "        Returns:\n",
    "            Array of selected indices\n",
    "        \"\"\"\n",
    "        # Use stratified sampling to ensure class balance\n",
    "        class_indices = [[] for _ in range(10)]  # CIFAR-10 has 10 classes\n",
    "        \n",
    "        print(\"Scanning dataset for class distribution...\")\n",
    "        # Use tqdm to show progress\n",
    "        for i in tqdm(range(len(self.full_dataset)), desc=\"Indexing dataset\"):\n",
    "            _, label = self.full_dataset[i]\n",
    "            class_indices[label].append(i)\n",
    "        \n",
    "        # Select equal number of samples from each class\n",
    "        samples_per_class = n_samples // 10\n",
    "        selected_indices = []\n",
    "        \n",
    "        print(f\"Selecting ~{samples_per_class} samples per class...\")\n",
    "        # Use tqdm for class selection\n",
    "        for class_idx in tqdm(range(10), desc=\"Selecting samples by class\"):\n",
    "            indices = np.random.choice(class_indices[class_idx], \n",
    "                                    min(samples_per_class, len(class_indices[class_idx])), \n",
    "                                    replace=False)\n",
    "            selected_indices.extend(indices)\n",
    "        \n",
    "        # If we don't have enough samples, fill the rest randomly\n",
    "        if len(selected_indices) < n_samples:\n",
    "            remaining = n_samples - len(selected_indices)\n",
    "            print(f\"Need {remaining} more samples to reach target, selecting randomly...\")\n",
    "            all_indices = set(range(len(self.full_dataset)))\n",
    "            remaining_indices = list(all_indices - set(selected_indices))\n",
    "            additional_indices = np.random.choice(remaining_indices, remaining, replace=False)\n",
    "            selected_indices.extend(additional_indices)\n",
    "        \n",
    "        print(f\"Selected {len(selected_indices)} initial samples\")\n",
    "        return np.array(selected_indices)\n",
    "    \n",
    "    def _save_weights(self):\n",
    "        \"\"\"Save the current weights to history\"\"\"\n",
    "        self.weight_history.append(self.weights.copy())\n",
    "    \n",
    "    def compute_uncertainty_scores(self, model, batch_size=128) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute uncertainty scores for all samples in the dataset\n",
    "        \n",
    "        Args:\n",
    "            model: The trained model\n",
    "            batch_size: Batch size for inference\n",
    "            \n",
    "        Returns:\n",
    "            Array of uncertainty scores for all samples\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        uncertainties = np.zeros(len(self.full_dataset))\n",
    "        \n",
    "        dataloader = DataLoader(\n",
    "            self.full_dataset, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            start_idx = 0\n",
    "            # Add tqdm progress bar\n",
    "            pbar = tqdm(dataloader, desc=\"Computing uncertainty scores\", leave=False)\n",
    "            for inputs, _ in pbar:\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = model(inputs)\n",
    "                probabilities = torch.softmax(outputs, dim=1)\n",
    "                \n",
    "                # Calculate entropy as uncertainty measure\n",
    "                entropy = -torch.sum(probabilities * torch.log(probabilities + 1e-10), dim=1)\n",
    "                \n",
    "                batch_size = inputs.size(0)\n",
    "                uncertainties[start_idx:start_idx+batch_size] = entropy.cpu().numpy()\n",
    "                start_idx += batch_size\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({'processed': f'{start_idx}/{len(self.full_dataset)}'})\n",
    "        \n",
    "        return uncertainties\n",
    "    \n",
    "    def compute_diversity_scores(self, model, batch_size=128) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute diversity scores based on feature space coverage\n",
    "        \n",
    "        Args:\n",
    "            model: The trained model\n",
    "            batch_size: Batch size for inference\n",
    "            \n",
    "        Returns:\n",
    "            Array of diversity scores for all samples\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        # Create a feature extractor from the model\n",
    "        feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "        feature_extractor.eval()\n",
    "        \n",
    "        # Get features for currently selected samples\n",
    "        selected_features = []\n",
    "        selected_subset = Subset(self.full_dataset, self.current_indices)\n",
    "        selected_loader = DataLoader(\n",
    "            selected_subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Add tqdm progress bar for feature extraction\n",
    "            pbar_extract = tqdm(selected_loader, desc=\"Extracting features for selected samples\", leave=False)\n",
    "            for inputs, _ in pbar_extract:\n",
    "                inputs = inputs.to(self.device)\n",
    "                features = feature_extractor(inputs)\n",
    "                selected_features.append(features.squeeze().cpu().numpy())\n",
    "        \n",
    "        if len(selected_features) > 0:\n",
    "            selected_features = np.vstack(selected_features)\n",
    "        else:\n",
    "            selected_features = np.array([]).reshape(0, 512)  # ResNet18 feature dim is 512\n",
    "        \n",
    "        # Compute diversity scores for all samples\n",
    "        diversity_scores = np.zeros(len(self.full_dataset))\n",
    "        \n",
    "        dataloader = DataLoader(\n",
    "            self.full_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            start_idx = 0\n",
    "            # Add tqdm progress bar for diversity computation\n",
    "            pbar_diversity = tqdm(dataloader, desc=\"Computing diversity scores\", leave=False)\n",
    "            for inputs, _ in pbar_diversity:\n",
    "                inputs = inputs.to(self.device)\n",
    "                features = feature_extractor(inputs)\n",
    "                batch_features = features.squeeze().cpu().numpy()\n",
    "                \n",
    "                batch_size = inputs.size(0)\n",
    "                \n",
    "                if len(selected_features) > 0:\n",
    "                    # For each sample, compute minimum distance to any selected sample\n",
    "                    for i in range(batch_size):\n",
    "                        if batch_features.ndim == 1:  # Handle batch of size 1\n",
    "                            sample_features = batch_features.reshape(1, -1)\n",
    "                        else:\n",
    "                            sample_features = batch_features[i].reshape(1, -1)\n",
    "                        \n",
    "                        # Compute distances to all selected samples\n",
    "                        distances = np.linalg.norm(selected_features - sample_features, axis=1)\n",
    "                        min_distance = np.min(distances) if len(distances) > 0 else float('inf')\n",
    "                        diversity_scores[start_idx + i] = min_distance\n",
    "                else:\n",
    "                    # If no samples are selected yet, assign high diversity to all\n",
    "                    diversity_scores[start_idx:start_idx+batch_size] = 1.0\n",
    "                \n",
    "                start_idx += batch_size\n",
    "                # Update progress bar\n",
    "                pbar_diversity.set_postfix({'processed': f'{start_idx}/{len(self.full_dataset)}'})\n",
    "        \n",
    "        return diversity_scores\n",
    "    \n",
    "    def compute_class_balance_scores(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute class balance scores to address imbalance\n",
    "        \n",
    "        Returns:\n",
    "            Array of class balance scores for all samples\n",
    "        \"\"\"\n",
    "        # Count current class distribution\n",
    "        class_counts = Counter([self.full_dataset[i][1] for i in self.current_indices])\n",
    "        \n",
    "        # Compute inverse frequency for each class (higher score for underrepresented classes)\n",
    "        total_samples = len(self.current_indices)\n",
    "        class_weights = {c: total_samples / (count + 1) for c, count in class_counts.items()}\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        max_weight = max(class_weights.values()) if class_weights else 1.0\n",
    "        class_weights = {c: w / max_weight for c, w in class_weights.items()}\n",
    "        \n",
    "        # Fill in any missing classes\n",
    "        for c in range(10):  # CIFAR-10 has 10 classes\n",
    "            if c not in class_weights:\n",
    "                class_weights[c] = 1.0  # Maximum weight for missing classes\n",
    "        \n",
    "        # Assign scores based on class\n",
    "        balance_scores = np.zeros(len(self.full_dataset))\n",
    "        for i in range(len(self.full_dataset)):\n",
    "            _, label = self.full_dataset[i]\n",
    "            balance_scores[i] = class_weights[label]\n",
    "        \n",
    "        return balance_scores\n",
    "    \n",
    "    def compute_boundary_scores(self, model, batch_size=128) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute boundary scores for samples near decision boundaries\n",
    "        \n",
    "        Args:\n",
    "            model: The trained model\n",
    "            batch_size: Batch size for inference\n",
    "            \n",
    "        Returns:\n",
    "            Array of boundary scores for all samples\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        boundary_scores = np.zeros(len(self.full_dataset))\n",
    "        \n",
    "        dataloader = DataLoader(\n",
    "            self.full_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            start_idx = 0\n",
    "            # Add tqdm progress bar\n",
    "            pbar = tqdm(dataloader, desc=\"Computing boundary scores\", leave=False)\n",
    "            for inputs, _ in pbar:\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = model(inputs)\n",
    "                probabilities = torch.softmax(outputs, dim=1)\n",
    "                \n",
    "                # Get top-2 probabilities\n",
    "                top_values, _ = torch.topk(probabilities, k=2, dim=1)\n",
    "                \n",
    "                # Boundary score = 1 - (p_max - p_second)\n",
    "                margin = top_values[:, 0] - top_values[:, 1]\n",
    "                score = 1.0 - margin\n",
    "                \n",
    "                batch_size = inputs.size(0)\n",
    "                boundary_scores[start_idx:start_idx+batch_size] = score.cpu().numpy()\n",
    "                start_idx += batch_size\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({'processed': f'{start_idx}/{len(self.full_dataset)}'})\n",
    "        \n",
    "        return boundary_scores\n",
    "    \n",
    "    def normalize_scores(self, scores: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Normalize scores to zero mean and unit variance\n",
    "        \n",
    "        Args:\n",
    "            scores: Array of scores\n",
    "            \n",
    "        Returns:\n",
    "            Normalized scores\n",
    "        \"\"\"\n",
    "        mean = np.mean(scores)\n",
    "        std = np.std(scores)\n",
    "        if std == 0:\n",
    "            return np.zeros_like(scores)\n",
    "        return (scores - mean) / (std + 1e-8)\n",
    "    \n",
    "    def select_samples(self, model, n_samples: int, current_metrics: Optional[Dict] = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Select the next batch of samples using the SPARROW algorithm with meta-agent guidance\n",
    "        \n",
    "        Args:\n",
    "            model: The trained model\n",
    "            n_samples: Number of samples to select\n",
    "            current_metrics: Optional dictionary of current performance metrics\n",
    "            \n",
    "        Returns:\n",
    "            Indices of selected samples\n",
    "        \"\"\"\n",
    "        print(f\"\\nSelecting {n_samples} new samples...\")\n",
    "        \n",
    "        # Compute scores for each strategy\n",
    "        with tqdm(total=4, desc=\"Computing selection scores\", leave=False) as pbar:\n",
    "            pbar.set_postfix({'strategy': 'uncertainty'})\n",
    "            uncertainty_scores = self.compute_uncertainty_scores(model)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            pbar.set_postfix({'strategy': 'diversity'})\n",
    "            diversity_scores = self.compute_diversity_scores(model)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            pbar.set_postfix({'strategy': 'class balance'})\n",
    "            class_balance_scores = self.compute_class_balance_scores()\n",
    "            pbar.update(1)\n",
    "            \n",
    "            pbar.set_postfix({'strategy': 'boundary'})\n",
    "            boundary_scores = self.compute_boundary_scores(model)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # Normalize scores\n",
    "        uncertainty_scores = self.normalize_scores(uncertainty_scores)\n",
    "        diversity_scores = self.normalize_scores(diversity_scores)\n",
    "        class_balance_scores = self.normalize_scores(class_balance_scores)\n",
    "        boundary_scores = self.normalize_scores(boundary_scores)\n",
    "        \n",
    "        # Get class distribution\n",
    "        class_distribution = Counter([self.full_dataset[i][1] for i in self.current_indices])\n",
    "        \n",
    "        # Evaluate per-strategy performance by selecting small batches with each strategy\n",
    "        print(\"Evaluating strategy performance...\")\n",
    "        strategy_performances = self._evaluate_strategy_performances(\n",
    "            model, \n",
    "            {\n",
    "                \"S_U\": uncertainty_scores,\n",
    "                \"S_D\": diversity_scores,\n",
    "                \"S_C\": class_balance_scores,\n",
    "                \"S_B\": boundary_scores\n",
    "            }, \n",
    "            n_eval_samples=min(100, n_samples // 4)\n",
    "        )\n",
    "        \n",
    "        # Extract feature statistics for additional guidance\n",
    "        print(\"Computing feature statistics...\")\n",
    "        feature_statistics = self._compute_feature_statistics(model)\n",
    "        \n",
    "        # Update learning state\n",
    "        accuracy = current_metrics.get(\"accuracy\", 0.5) if current_metrics else 0.5\n",
    "        loss = current_metrics.get(\"loss\", 1.0) if current_metrics else 1.0\n",
    "        \n",
    "        # Fallback to basic weighted allocation by default\n",
    "        print(\"Using weighted allocation based on current weights...\")\n",
    "        total_weight = sum(self.weights.values())\n",
    "        allocation = {s: int(n_samples * (w / total_weight)) for s, w in self.weights.items()}\n",
    "        \n",
    "        # Ensure all samples are allocated (handle rounding errors)\n",
    "        allocated = sum(allocation.values())\n",
    "        if allocated < n_samples:\n",
    "            # Add remaining samples to the strategy with highest weight\n",
    "            dominant_strategy = max(self.weights.items(), key=lambda x: x[1])[0]\n",
    "            allocation[dominant_strategy] += (n_samples - allocated)\n",
    "            \n",
    "        # Try to use meta-controller if available\n",
    "        try:\n",
    "            if hasattr(self, 'meta_controller') and self.meta_controller is not None:\n",
    "                print(\"Using meta-controller for strategic allocation...\")\n",
    "                state = self.meta_controller.update_state(\n",
    "                    epoch=self.current_epoch,\n",
    "                    accuracy=accuracy,\n",
    "                    loss=loss,\n",
    "                    class_distribution=class_distribution,\n",
    "                    dataset_size=len(self.current_indices),\n",
    "                    strategy_performances=strategy_performances,\n",
    "                    feature_statistics=feature_statistics\n",
    "                )\n",
    "                \n",
    "                # Get sample allocation from meta-controller\n",
    "                meta_allocation = self.meta_controller.get_sample_allocation(n_samples, state)\n",
    "                \n",
    "                # Update current weights with those from meta-controller\n",
    "                self.weights = self.meta_controller.get_current_weights()\n",
    "                self._save_weights()\n",
    "                \n",
    "                # Print strategy decision explanation (useful for debugging)\n",
    "                explanation = self.meta_controller.get_latest_explanation()\n",
    "                print(f\"Strategy selection: {explanation}\")\n",
    "                \n",
    "                # Use the meta-controller allocation\n",
    "                allocation = meta_allocation\n",
    "        except (AttributeError, NameError) as e:\n",
    "            print(f\"Meta-controller not available or error: {e}\")\n",
    "            print(\"Using fallback allocation based on current weights...\")\n",
    "        \n",
    "        # Print and visualize allocation\n",
    "        print(f\"Sample allocation: {allocation}\")\n",
    "        \n",
    "        # Create a visual representation of allocation\n",
    "        visual = \"\\nSample allocation: [\"\n",
    "        for strategy, count in allocation.items():\n",
    "            if count > 0:\n",
    "                # Use first letter of strategy for the visual (U, D, C, B)\n",
    "                visual += strategy[2] * (count * 50 // n_samples)\n",
    "        visual += \"]\\n\"\n",
    "        print(visual)\n",
    "        \n",
    "        # Select samples using each strategy according to allocation\n",
    "        selected_indices = []\n",
    "        strategy_pbar = tqdm(allocation.items(), desc=\"Selecting samples by strategy\", leave=False)\n",
    "        \n",
    "        for strategy, count in strategy_pbar:\n",
    "            if count <= 0:\n",
    "                continue\n",
    "                \n",
    "            strategy_pbar.set_postfix({'strategy': strategy, 'count': count})\n",
    "            \n",
    "            if strategy == \"S_U\":\n",
    "                strategy_indices = self._select_by_scores(uncertainty_scores, count)\n",
    "            elif strategy == \"S_D\":\n",
    "                strategy_indices = self._select_by_scores(diversity_scores, count)\n",
    "            elif strategy == \"S_C\":\n",
    "                strategy_indices = self._select_by_scores(class_balance_scores, count)\n",
    "            elif strategy == \"S_B\":\n",
    "                strategy_indices = self._select_by_scores(boundary_scores, count)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            selected_indices.extend(strategy_indices)\n",
    "        \n",
    "        # Ensure we have no duplicates and exactly n_samples\n",
    "        selected_indices = list(set(selected_indices))  # Remove duplicates\n",
    "        \n",
    "        # If we have too few, add more from the highest weighted strategy\n",
    "        if len(selected_indices) < n_samples:\n",
    "            print(f\"Need {n_samples - len(selected_indices)} more samples to reach target\")\n",
    "            dominant_strategy = max(self.weights.items(), key=lambda x: x[1])[0]\n",
    "            additional_needed = n_samples - len(selected_indices)\n",
    "            \n",
    "            if dominant_strategy == \"S_U\":\n",
    "                additional_scores = uncertainty_scores\n",
    "            elif dominant_strategy == \"S_D\":\n",
    "                additional_scores = diversity_scores\n",
    "            elif dominant_strategy == \"S_C\":\n",
    "                additional_scores = class_balance_scores\n",
    "            else:  # S_B\n",
    "                additional_scores = boundary_scores\n",
    "                \n",
    "            additional_indices = self._select_by_scores(\n",
    "                additional_scores, \n",
    "                additional_needed, \n",
    "                exclude=selected_indices\n",
    "            )\n",
    "            selected_indices.extend(additional_indices)\n",
    "        \n",
    "        # If we have too many, truncate\n",
    "        if len(selected_indices) > n_samples:\n",
    "            print(f\"Truncating {len(selected_indices) - n_samples} excess samples\")\n",
    "            selected_indices = selected_indices[:n_samples]\n",
    "        \n",
    "        # Increment epoch counter\n",
    "        self.current_epoch += 1\n",
    "        \n",
    "        print(f\"Selected {len(selected_indices)} new samples\")\n",
    "        \n",
    "        return np.array(selected_indices)\n",
    "    \n",
    "    def _select_by_scores(self, scores, count, exclude=None):\n",
    "        \"\"\"\n",
    "        Select top scoring samples that aren't already in current_indices or exclude list\n",
    "        \"\"\"\n",
    "        exclude_set = set(self.current_indices)\n",
    "        if exclude:\n",
    "            exclude_set.update(exclude)\n",
    "            \n",
    "        # Create mask for available indices\n",
    "        mask = np.ones(len(self.full_dataset), dtype=bool)\n",
    "        mask[list(exclude_set)] = False\n",
    "        available_indices = np.arange(len(self.full_dataset))[mask]\n",
    "        available_scores = scores[mask]\n",
    "        \n",
    "        # Select top-scoring samples\n",
    "        if len(available_indices) <= count:\n",
    "            return available_indices\n",
    "        \n",
    "        top_indices = np.argsort(available_scores)[-count:]\n",
    "        selected = available_indices[top_indices]\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def _evaluate_strategy_performances(self, model, strategy_scores, n_eval_samples=50):\n",
    "        \"\"\"\n",
    "        Evaluate the performance contribution of each strategy\n",
    "        \n",
    "        Args:\n",
    "            model: The current model\n",
    "            strategy_scores: Dictionary of score arrays for each strategy\n",
    "            n_eval_samples: Number of samples to use for evaluation\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of performance metrics for each strategy\n",
    "        \"\"\"\n",
    "        base_model = model\n",
    "        performances = {}\n",
    "        \n",
    "        # Get a small validation set from test data (if available)\n",
    "        try:\n",
    "            testset = torchvision.datasets.CIFAR10(\n",
    "                root='./data', train=False, download=False,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                ])\n",
    "            )\n",
    "            val_indices = np.random.choice(len(testset), 1000, replace=False)\n",
    "            val_subset = Subset(testset, val_indices)\n",
    "            val_loader = DataLoader(val_subset, batch_size=128, shuffle=False, num_workers=2)\n",
    "        except:\n",
    "            # If no test data available, use a portion of current coreset\n",
    "            if len(self.current_indices) >= 200:\n",
    "                val_indices = np.random.choice(self.current_indices, 200, replace=False)\n",
    "                val_subset = Subset(self.full_dataset, val_indices)\n",
    "                val_loader = DataLoader(val_subset, batch_size=128, shuffle=False, num_workers=2)\n",
    "            else:\n",
    "                # Not enough data for validation, return empty performance dict\n",
    "                return {}\n",
    "        \n",
    "        # Evaluate base model performance\n",
    "        base_acc = self._quick_eval_model(base_model, val_loader)\n",
    "        \n",
    "        # For each strategy, select samples and train briefly\n",
    "        strategy_pbar = tqdm(strategy_scores.items(), desc=\"Evaluating strategy performance\", leave=False)\n",
    "        for strategy_name, scores in strategy_pbar:\n",
    "            strategy_pbar.set_postfix({'strategy': strategy_name})\n",
    "            \n",
    "            # Select samples using only this strategy\n",
    "            strategy_indices = self._select_by_scores(scores, n_eval_samples)\n",
    "            \n",
    "            if len(strategy_indices) == 0:\n",
    "                performances[strategy_name] = 0.0\n",
    "                continue\n",
    "            \n",
    "            # Create a temporary dataset with these samples\n",
    "            temp_indices = np.concatenate([self.current_indices, strategy_indices])\n",
    "            temp_subset = Subset(self.full_dataset, temp_indices)\n",
    "            temp_loader = DataLoader(\n",
    "                temp_subset,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                num_workers=2\n",
    "            )\n",
    "            \n",
    "            # Clone the model for this strategy evaluation\n",
    "            import copy\n",
    "            strategy_model = copy.deepcopy(base_model)\n",
    "            \n",
    "            # Train briefly\n",
    "            strategy_model.train()\n",
    "            optimizer = torch.optim.Adam(strategy_model.parameters(), lr=0.001)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            train_pbar = tqdm(range(3), desc=f\"Training with {strategy_name}\", leave=False)\n",
    "            for _ in train_pbar:\n",
    "                batch_losses = []\n",
    "                for inputs, targets in temp_loader:\n",
    "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = strategy_model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    batch_losses.append(loss.item())\n",
    "                \n",
    "                # Update progress bar\n",
    "                train_pbar.set_postfix({'loss': f'{np.mean(batch_losses):.4f}'})\n",
    "            \n",
    "            # Evaluate performance\n",
    "            strategy_acc = self._quick_eval_model(strategy_model, val_loader)\n",
    "            improvement = strategy_acc - base_acc\n",
    "            performances[strategy_name] = max(0, improvement)\n",
    "            \n",
    "            # Update strategy performance bar\n",
    "            strategy_pbar.set_postfix({\n",
    "                'strategy': strategy_name, \n",
    "                'acc': f'{strategy_acc:.4f}', \n",
    "                'impr': f'{improvement:.4f}'\n",
    "            })\n",
    "            \n",
    "            # Clean up to avoid memory issues\n",
    "            del strategy_model\n",
    "            \n",
    "        return performances\n",
    "    \n",
    "    def _quick_eval_model(self, model, data_loader):\n",
    "        \"\"\"Quick evaluation of model accuracy\"\"\"\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in data_loader:\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        return correct / total\n",
    "    \n",
    "    def _compute_feature_statistics(self, model):\n",
    "        \"\"\"\n",
    "        Compute statistics about the feature space\n",
    "        \n",
    "        Args:\n",
    "            model: The current model\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of feature statistics\n",
    "        \"\"\"\n",
    "        # Create feature extractor\n",
    "        feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "        feature_extractor.to(self.device)\n",
    "        feature_extractor.eval()\n",
    "        \n",
    "        # Sample a subset of current coreset for efficiency\n",
    "        if len(self.current_indices) > 500:\n",
    "            sample_indices = np.random.choice(self.current_indices, 500, replace=False)\n",
    "        else:\n",
    "            sample_indices = self.current_indices\n",
    "            \n",
    "        sample_subset = Subset(self.full_dataset, sample_indices)\n",
    "        sample_loader = DataLoader(sample_subset, batch_size=128, shuffle=False, num_workers=2)\n",
    "        \n",
    "        # Extract features and labels\n",
    "        features = []\n",
    "        labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Add tqdm progress bar\n",
    "            pbar = tqdm(sample_loader, desc=\"Computing feature statistics\", leave=False)\n",
    "            for inputs, targets in pbar:\n",
    "                inputs = inputs.to(self.device)\n",
    "                batch_features = feature_extractor(inputs).squeeze()\n",
    "                features.append(batch_features.cpu().numpy())\n",
    "                labels.extend(targets.numpy())\n",
    "                pbar.set_postfix({'features': len(features)})\n",
    "                \n",
    "        if len(features) > 0:\n",
    "            features = np.vstack(features)\n",
    "            labels = np.array(labels)\n",
    "            \n",
    "            # Compute statistics\n",
    "            # 1. Feature diversity - average distance between samples\n",
    "            from sklearn.metrics import pairwise_distances\n",
    "            # Add progress indication\n",
    "            print(\"Computing pairwise distances...\")\n",
    "            if len(features) > 100:  # If too many samples, use a subset for efficiency\n",
    "                subset_idx = np.random.choice(len(features), 100, replace=False)\n",
    "                subset_features = features[subset_idx]\n",
    "                distances = pairwise_distances(subset_features)\n",
    "            else:\n",
    "                distances = pairwise_distances(features)\n",
    "                \n",
    "            feature_diversity = np.mean(distances) / np.max(distances)\n",
    "            \n",
    "            # 2. Feature redundancy - correlation between dimensions\n",
    "            print(\"Computing feature correlations...\")\n",
    "            if features.shape[1] > 1:  # Only if we have multiple feature dimensions\n",
    "                corr_matrix = np.corrcoef(features.T)\n",
    "                feature_redundancy = np.mean(np.abs(corr_matrix - np.eye(corr_matrix.shape[0])))\n",
    "            else:\n",
    "                feature_redundancy = 0.0\n",
    "            \n",
    "            # 3. Class separation - ratio of between-class to within-class distance\n",
    "            print(\"Computing class separation...\")\n",
    "            class_ids = np.unique(labels)\n",
    "            if len(class_ids) > 1:\n",
    "                within_class_dist = []\n",
    "                # Use tqdm for class iteration\n",
    "                for c in tqdm(class_ids, desc=\"Within-class distances\", leave=False):\n",
    "                    class_features = features[labels == c]\n",
    "                    if len(class_features) > 1:\n",
    "                        class_distances = pairwise_distances(class_features)\n",
    "                        within_class_dist.append(np.mean(class_distances))\n",
    "                \n",
    "                between_class_dist = []\n",
    "                # Use tqdm for class pair iteration\n",
    "                pairs = [(i, c1, c2) for i, c1 in enumerate(class_ids[:-1]) \n",
    "                        for c2 in class_ids[i+1:]]\n",
    "                for _, c1, c2 in tqdm(pairs, desc=\"Between-class distances\", leave=False):\n",
    "                    class1_features = features[labels == c1]\n",
    "                    class2_features = features[labels == c2]\n",
    "                    if len(class1_features) > 0 and len(class2_features) > 0:\n",
    "                        between_distances = pairwise_distances(class1_features, class2_features)\n",
    "                        between_class_dist.append(np.mean(between_distances))\n",
    "                \n",
    "                if within_class_dist and between_class_dist:\n",
    "                    class_separation = np.mean(between_class_dist) / np.mean(within_class_dist)\n",
    "                else:\n",
    "                    class_separation = 1.0\n",
    "            else:\n",
    "                class_separation = 1.0\n",
    "            \n",
    "            return {\n",
    "                \"feature_diversity\": feature_diversity,\n",
    "                \"feature_redundancy\": feature_redundancy,\n",
    "                \"class_separation\": class_separation\n",
    "            }\n",
    "        \n",
    "        # Default values if we couldn't compute statistics\n",
    "        return {\n",
    "            \"feature_diversity\": 0.5,\n",
    "            \"feature_redundancy\": 0.5,\n",
    "            \"class_separation\": 0.5\n",
    "        }\n",
    "\n",
    "    def update_weights(self, model, train_loader, val_loader) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Update strategy weights based on performance and meta-agent guidance\n",
    "        \n",
    "        Args:\n",
    "            model: The trained model\n",
    "            train_loader: DataLoader for training data\n",
    "            val_loader: DataLoader for validation data\n",
    "            \n",
    "        Returns:\n",
    "            Updated weights\n",
    "        \"\"\"\n",
    "        print(\"\\nUpdating strategy weights...\")\n",
    "        \n",
    "        # Evaluate model performance\n",
    "        model.eval()\n",
    "        accuracy = self._quick_eval_model(model, val_loader)\n",
    "        \n",
    "        # Extract training loss\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        loss_pbar = tqdm(train_loader, desc=\"Computing training loss\", leave=False)\n",
    "        for inputs, targets in loss_pbar:\n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            train_loss += loss.item()\n",
    "            loss_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Get class distribution\n",
    "        class_distribution = Counter([self.full_dataset[i][1] for i in self.current_indices])\n",
    "        \n",
    "        # Compute strategy performances\n",
    "        with tqdm(total=4, desc=\"Computing strategy scores\", leave=False) as pbar:\n",
    "            pbar.set_postfix({'stage': 'uncertainty'})\n",
    "            uncertainty_scores = self.compute_uncertainty_scores(model)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            pbar.set_postfix({'stage': 'diversity'})\n",
    "            diversity_scores = self.compute_diversity_scores(model)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            pbar.set_postfix({'stage': 'class balance'})\n",
    "            class_balance_scores = self.compute_class_balance_scores()\n",
    "            pbar.update(1)\n",
    "            \n",
    "            pbar.set_postfix({'stage': 'boundary'})\n",
    "            boundary_scores = self.compute_boundary_scores(model)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # Evaluate strategy performances\n",
    "        strategy_performances = self._evaluate_strategy_performances(\n",
    "            model, \n",
    "            {\n",
    "                \"S_U\": uncertainty_scores,\n",
    "                \"S_D\": diversity_scores,\n",
    "                \"S_C\": class_balance_scores,\n",
    "                \"S_B\": boundary_scores\n",
    "            }, \n",
    "            n_eval_samples=50\n",
    "        )\n",
    "        \n",
    "        # Compute feature statistics\n",
    "        print(\"Computing feature statistics...\")\n",
    "        feature_statistics = self._compute_feature_statistics(model)\n",
    "        \n",
    "        # Default fallback - use simple reward-based weight update\n",
    "        print(\"Using reward-based weight update...\")\n",
    "        alpha_values = {s: 1.0 + 10.0 * strategy_performances.get(s, 0.0) for s in self.strategies}\n",
    "        \n",
    "        # Apply temperature to control exploration/exploitation\n",
    "        new_weights = {}\n",
    "        denominator = sum(np.exp(a / self.temperature) for a in alpha_values.values())\n",
    "        for s in self.strategies:\n",
    "            new_weights[s] = np.exp(alpha_values[s] / self.temperature) / denominator\n",
    "        \n",
    "        # Adjust temperature - decrease over time\n",
    "        self.temperature = max(0.1, self.temperature * 0.95)\n",
    "        \n",
    "        # Blend with current weights for stability\n",
    "        for s in self.strategies:\n",
    "            self.weights[s] = 0.7 * self.weights[s] + 0.3 * new_weights[s]\n",
    "        \n",
    "        # Normalize weights\n",
    "        total = sum(self.weights.values())\n",
    "        self.weights = {s: w / total for s, w in self.weights.items()}\n",
    "        \n",
    "        # Try to use meta-controller if available\n",
    "        try:\n",
    "            if hasattr(self, 'meta_controller') and self.meta_controller is not None:\n",
    "                print(\"Using meta-controller for weight update...\")\n",
    "                state = self.meta_controller.update_state(\n",
    "                    epoch=self.current_epoch,\n",
    "                    accuracy=accuracy,\n",
    "                    loss=train_loss,\n",
    "                    class_distribution=class_distribution,\n",
    "                    dataset_size=len(self.current_indices),\n",
    "                    strategy_performances=strategy_performances,\n",
    "                    feature_statistics=feature_statistics\n",
    "                )\n",
    "                \n",
    "                # Get new weights from meta-controller\n",
    "                meta_weights = self.meta_controller.get_current_weights()\n",
    "                \n",
    "                # Print explanation of decision\n",
    "                explanation = self.meta_controller.get_latest_explanation()\n",
    "                print(f\"Strategy update: {explanation}\")\n",
    "                \n",
    "                # Use the meta-controller weights\n",
    "                self.weights = meta_weights\n",
    "        except (AttributeError, NameError) as e:\n",
    "            print(f\"Meta-controller not available or error: {e}\")\n",
    "            print(\"Using fallback weight update method (already applied)...\")\n",
    "        \n",
    "        # Save updated weights\n",
    "        self._save_weights()\n",
    "        \n",
    "        # Increment epoch counter\n",
    "        self.current_epoch += 1\n",
    "        \n",
    "        # Print new weights\n",
    "        print(f\"New strategy weights: {self.weights}\")\n",
    "        \n",
    "        return self.weights\n",
    "        \n",
    "    def get_coreset(self, model=None, n_additional=None, current_metrics=None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the current coreset (or expand it if model is provided)\n",
    "        \n",
    "        Args:\n",
    "            model: Optional model to use for selecting additional samples\n",
    "            n_additional: Optional number of additional samples to select\n",
    "            current_metrics: Optional dictionary of current performance metrics\n",
    "            \n",
    "        Returns:\n",
    "            Indices of the coreset\n",
    "        \"\"\"\n",
    "        if model is not None and n_additional is not None and n_additional > 0:\n",
    "            # Select additional samples\n",
    "            try:\n",
    "                # Try using the enhanced method with metrics\n",
    "                new_indices = self.select_samples(\n",
    "                    model,\n",
    "                    min(n_additional, self.budget - len(self.current_indices)),\n",
    "                    current_metrics\n",
    "                )\n",
    "            except TypeError:\n",
    "                # Fallback to simpler method if we have a compatibility issue\n",
    "                new_indices = self.select_samples(\n",
    "                    model,\n",
    "                    min(n_additional, self.budget - len(self.current_indices))\n",
    "                )\n",
    "            \n",
    "            # Add to current indices\n",
    "            self.current_indices = np.concatenate([self.current_indices, new_indices])\n",
    "        \n",
    "        return self.current_indices\n",
    "    \n",
    "    def get_coreset_subset(self) -> Subset:\n",
    "        \"\"\"\n",
    "        Get a PyTorch Subset representing the coreset\n",
    "        \n",
    "        Returns:\n",
    "            Subset containing the coreset\n",
    "        \"\"\"\n",
    "        return Subset(self.full_dataset, self.current_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ed91ce-ab03-4aa9-b2b9-b6e808c5adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPARROWTrainer:\n",
    "    \"\"\"Trainer class for SPARROW coreset selection\"\"\"\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        \n",
    "        # Enhanced device selection with MPS support\n",
    "        if args.device:\n",
    "            self.device = torch.device(args.device)\n",
    "        else:\n",
    "            # Try CUDA first\n",
    "            if torch.cuda.is_available():\n",
    "                self.device = torch.device(\"cuda\")\n",
    "            # Then try MPS (Apple Silicon)\n",
    "            elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "                self.device = torch.device(\"mps\")\n",
    "            # Fall back to CPU\n",
    "            else:\n",
    "                self.device = torch.device(\"cpu\")\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        self.setup_data()\n",
    "        self.setup_model()\n",
    "        self.setup_optimizer()\n",
    "        \n",
    "        # Set up the coreset selector\n",
    "        self.coreset_selector = SparrowCoresetSelector(\n",
    "            self.full_dataset, \n",
    "            budget=self.args.max_budget,\n",
    "            initial_samples=self.args.initial_sample_size,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        self.current_indices = self.coreset_selector.current_indices\n",
    "        self.update_train_loader()\n",
    "        \n",
    "        # Metrics tracking\n",
    "        self.metrics = []\n",
    "        self.best_accuracy = 0.0\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Set up TensorBoard writer\n",
    "        current_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        if self.args.tensorboard_dir:\n",
    "            tensorboard_dir = self.args.tensorboard_dir\n",
    "        else:\n",
    "            tensorboard_dir = os.path.join(self.args.save_path, 'tensorboard', current_time)\n",
    "        \n",
    "        os.makedirs(tensorboard_dir, exist_ok=True)\n",
    "        self.writer = SummaryWriter(tensorboard_dir)\n",
    "        print(f\"TensorBoard logs will be saved to {tensorboard_dir}\")\n",
    "        \n",
    "        # Add model graph to TensorBoard\n",
    "        dummy_input = torch.randn(1, 3, 32, 32, device=self.device)  # CIFAR input size\n",
    "        self.writer.add_graph(self.model, dummy_input)\n",
    "        \n",
    "        # Visualize the learning rate schedule\n",
    "        # Log the planned learning rate schedule\n",
    "        temp_optimizer = torch.optim.Adam(self.model.parameters(), lr=self.args.lr)\n",
    "        temp_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(temp_optimizer, T_max=self.args.epochs)\n",
    "        lrs = []\n",
    "        for i in range(self.args.epochs):\n",
    "            lrs.append(temp_optimizer.param_groups[0]['lr'])\n",
    "            temp_scheduler.step()\n",
    "        \n",
    "        # Plot learning rate schedule\n",
    "        fig, ax = plt.figure(figsize=(10, 5)), plt.subplot(111)\n",
    "        ax.plot(range(len(lrs)), lrs)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Learning Rate')\n",
    "        ax.set_title('Learning Rate Schedule')\n",
    "        ax.grid(True)\n",
    "        self.writer.add_figure('Optimizer/LRSchedule', fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "    def setup_data(self):\n",
    "        \"\"\"Set up datasets and initial data loaders\"\"\"\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        \n",
    "        # Load CIFAR-10 dataset\n",
    "        self.full_dataset = torchvision.datasets.CIFAR10(\n",
    "            root='./data', train=True, download=True, transform=transform_train\n",
    "        )\n",
    "        self.test_dataset = torchvision.datasets.CIFAR10(\n",
    "            root='./data', train=False, download=True, transform=transform_test\n",
    "        )\n",
    "        \n",
    "        # Create test loader\n",
    "        self.test_loader = DataLoader(\n",
    "            self.test_dataset, \n",
    "            batch_size=self.args.batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=self.args.workers\n",
    "        )\n",
    "        \n",
    "        # For validation, we'll use 10% of the test set\n",
    "        test_size = len(self.test_dataset)\n",
    "        val_size = test_size // 10\n",
    "        val_indices = np.random.choice(test_size, val_size, replace=False)\n",
    "        self.val_loader = DataLoader(\n",
    "            Subset(self.test_dataset, val_indices),\n",
    "            batch_size=self.args.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.args.workers\n",
    "        )\n",
    "\n",
    "    def setup_model(self):\n",
    "        \"\"\"Initialize the model\"\"\"\n",
    "        self.model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 10)  # 10 classes for CIFAR-10\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def setup_optimizer(self):\n",
    "        \"\"\"Set up optimizer and loss function\"\"\"\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.args.lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.args.epochs)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def update_train_loader(self):\n",
    "        \"\"\"Update the training data loader with current coreset\"\"\"\n",
    "        subset = Subset(self.full_dataset, self.current_indices)\n",
    "        self.train_loader = DataLoader(\n",
    "            subset, \n",
    "            batch_size=self.args.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=self.args.workers\n",
    "        )\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Use tqdm for progress bar\n",
    "        pbar = tqdm(self.train_loader, desc=f'Epoch {self.current_epoch} [Train]', \n",
    "                   leave=False, dynamic_ncols=True)\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # Log training metrics per batch to TensorBoard\n",
    "            global_step = self.current_epoch * len(self.train_loader) + batch_idx\n",
    "            self.writer.add_scalar('Train/BatchLoss', loss.item(), global_step)\n",
    "            \n",
    "            # Update progress bar\n",
    "            acc = 100. * correct / total\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}', \n",
    "                'acc': f'{acc:.2f}%',\n",
    "                'lr': f'{self.optimizer.param_groups[0][\"lr\"]:.6f}'\n",
    "            })\n",
    "            \n",
    "            if batch_idx % self.args.print_freq == 0:\n",
    "                print(f'Epoch: {self.current_epoch} '\n",
    "                      f'[{batch_idx * len(inputs)}/{len(self.train_loader.dataset)} '\n",
    "                      f'({100. * batch_idx / len(self.train_loader):.0f}%)] '\n",
    "                      f'Loss: {loss.item():.6f}')\n",
    "\n",
    "        return total_loss / len(self.train_loader), correct / total\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate the model on the test set\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        # Use tqdm for progress bar\n",
    "        pbar = tqdm(self.test_loader, desc='Evaluation', leave=False, dynamic_ncols=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in pbar:\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                current_correct = predicted.eq(targets).sum().item()\n",
    "                correct += current_correct\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar\n",
    "                acc = 100. * correct / total\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}', \n",
    "                    'acc': f'{acc:.2f}%'\n",
    "                })\n",
    "\n",
    "        accuracy = correct / total\n",
    "        f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "        precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "        recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "        conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "        \n",
    "        # Log confusion matrix to TensorBoard (once every 10 epochs)\n",
    "        if hasattr(self, 'current_epoch') and self.current_epoch % 10 == 0:\n",
    "            fig, ax = plt.figure(figsize=(10, 10)), plt.subplot(111)\n",
    "            cax = ax.matshow(conf_matrix)\n",
    "            plt.title('Confusion Matrix')\n",
    "            fig.colorbar(cax)\n",
    "            ax.set_xticklabels([''] + [str(i) for i in range(10)])\n",
    "            ax.set_yticklabels([''] + [str(i) for i in range(10)])\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('True')\n",
    "            self.writer.add_figure('Test/ConfusionMatrix', fig, self.current_epoch)\n",
    "\n",
    "        return total_loss / len(self.test_loader), accuracy, f1, precision, recall, conf_matrix\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the complete training pipeline\"\"\"\n",
    "        # Use trange for epoch progress\n",
    "        epoch_iterator = trange(self.args.epochs, desc=\"Training Progress\", dynamic_ncols=True)\n",
    "        \n",
    "        for self.current_epoch in epoch_iterator:\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            # Train for one epoch\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_loss, test_acc, f1, precision, recall, conf_matrix = self.evaluate()\n",
    "            \n",
    "            # Step the scheduler\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Log metrics to TensorBoard\n",
    "            self.writer.add_scalar('Train/Loss', train_loss, self.current_epoch)\n",
    "            self.writer.add_scalar('Train/Accuracy', train_acc, self.current_epoch)\n",
    "            self.writer.add_scalar('Test/Loss', test_loss, self.current_epoch)\n",
    "            self.writer.add_scalar('Test/Accuracy', test_acc, self.current_epoch)\n",
    "            self.writer.add_scalar('Test/F1', f1, self.current_epoch)\n",
    "            self.writer.add_scalar('Test/Precision', precision, self.current_epoch)\n",
    "            self.writer.add_scalar('Test/Recall', recall, self.current_epoch)\n",
    "            self.writer.add_scalar('Dataset/Size', len(self.current_indices), self.current_epoch)\n",
    "            self.writer.add_scalar('Optimizer/LearningRate', self.optimizer.param_groups[0]['lr'], self.current_epoch)\n",
    "            \n",
    "            # Log strategy weights to TensorBoard\n",
    "            for strategy, weight in self.coreset_selector.weights.items():\n",
    "                self.writer.add_scalar(f'Strategy/Weight_{strategy}', weight, self.current_epoch)\n",
    "            \n",
    "            # Add histograms of model parameters (every 10 epochs to avoid overhead)\n",
    "            if self.current_epoch % 10 == 0:\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    self.writer.add_histogram(f'Parameters/{name}', param.clone().cpu().data.numpy(), self.current_epoch)\n",
    "                    if param.grad is not None:\n",
    "                        self.writer.add_histogram(f'Gradients/{name}', param.grad.clone().cpu().data.numpy(), self.current_epoch)\n",
    "            \n",
    "            # Add class distribution visualization\n",
    "            if self.current_epoch % 20 == 0:\n",
    "                class_counts = Counter([self.full_dataset[i][1] for i in self.current_indices])\n",
    "                fig, ax = plt.figure(figsize=(10, 6)), plt.subplot(111)\n",
    "                classes = sorted(class_counts.keys())\n",
    "                counts = [class_counts[c] for c in classes]\n",
    "                ax.bar(classes, counts)\n",
    "                ax.set_xlabel('Class')\n",
    "                ax.set_ylabel('Count')\n",
    "                ax.set_title(f'Coreset Class Distribution at Epoch {self.current_epoch}')\n",
    "                self.writer.add_figure('Coreset/ClassDistribution', fig, self.current_epoch)\n",
    "                plt.close(fig)\n",
    "            \n",
    "            # Update strategy weights\n",
    "            if self.current_epoch % 5 == 0:  # Update every 5 epochs to save computation\n",
    "                strategy_weights = self.coreset_selector.update_weights(\n",
    "                    self.model, \n",
    "                    self.train_loader, \n",
    "                    self.val_loader\n",
    "                )\n",
    "                print(f\"Updated strategy weights: {strategy_weights}\")\n",
    "            \n",
    "            # Expand the coreset if needed\n",
    "            if len(self.current_indices) < self.args.max_budget:\n",
    "                n_additional = min(\n",
    "                    self.args.samples_per_epoch, \n",
    "                    self.args.max_budget - len(self.current_indices)\n",
    "                )\n",
    "                \n",
    "                # Provide metrics to the meta-agent\n",
    "                current_metrics = {\n",
    "                    \"accuracy\": test_acc,\n",
    "                    \"loss\": test_loss,\n",
    "                    \"f1\": f1,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall\n",
    "                }\n",
    "                \n",
    "                self.current_indices = self.coreset_selector.get_coreset(\n",
    "                    model=self.model,\n",
    "                    n_additional=n_additional,\n",
    "                    current_metrics=current_metrics\n",
    "                )\n",
    "                \n",
    "                # Update the training data loader\n",
    "                self.update_train_loader()\n",
    "                print(f\"Coreset expanded to {len(self.current_indices)} samples\")\n",
    "            \n",
    "            # Calculate time\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            total_time = time.time() - self.start_time\n",
    "            \n",
    "            # Log time metrics to TensorBoard\n",
    "            self.writer.add_scalar('Time/Epoch', epoch_time, self.current_epoch)\n",
    "            self.writer.add_scalar('Time/Total', total_time, self.current_epoch)\n",
    "            \n",
    "            # Log metrics\n",
    "            metrics = {\n",
    "                \"epoch\": self.current_epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"test_loss\": test_loss,\n",
    "                \"test_acc\": test_acc,\n",
    "                \"f1_score\": f1,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"dataset_size\": len(self.current_indices),\n",
    "                \"strategy_weights\": self.coreset_selector.weights,\n",
    "                \"epoch_time\": epoch_time,\n",
    "                \"total_time\": total_time\n",
    "            }\n",
    "            self.metrics.append(metrics)\n",
    "            \n",
    "            # Update progress bar with summary\n",
    "            epoch_iterator.set_postfix({\n",
    "                'train_loss': f'{train_loss:.4f}',\n",
    "                'train_acc': f'{train_acc:.4f}',\n",
    "                'test_acc': f'{test_acc:.4f}',\n",
    "                'dataset': f'{len(self.current_indices)}/{self.args.max_budget}'\n",
    "            })\n",
    "            \n",
    "            print(f\"Epoch {self.current_epoch+1}/{self.args.epochs}, \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                  f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, \"\n",
    "                  f\"F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, \"\n",
    "                  f\"Epoch Time: {epoch_time:.2f}s, Total Time: {total_time:.2f}s\")\n",
    "            \n",
    "            # Save checkpoint if best accuracy\n",
    "            if test_acc > self.best_accuracy:\n",
    "                self.best_accuracy = test_acc\n",
    "                self.save_checkpoint({\n",
    "                    'epoch': self.current_epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'best_accuracy': self.best_accuracy,\n",
    "                    'current_indices': self.current_indices,\n",
    "                    'strategy_weights': self.coreset_selector.weights\n",
    "                }, os.path.join(self.args.save_path, 'best_model.pth'))\n",
    "                \n",
    "                # Log best model to TensorBoard\n",
    "                self.writer.add_scalar('Best/Accuracy', test_acc, self.current_epoch)\n",
    "                self.writer.add_scalar('Best/Epoch', self.current_epoch, self.current_epoch)\n",
    "        \n",
    "        # Save final statistics\n",
    "        self.save_final_statistics()\n",
    "        \n",
    "        # Print TensorBoard viewing instructions\n",
    "        if self.args.tensorboard_dir:\n",
    "            tensorboard_dir = self.args.tensorboard_dir\n",
    "        else:\n",
    "            current_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "            tensorboard_dir = os.path.join(self.args.save_path, 'tensorboard', current_time)\n",
    "        \n",
    "        print(f\"\\nTraining completed! To view TensorBoard logs, run:\")\n",
    "        print(f\"tensorboard --logdir={tensorboard_dir}\")\n",
    "        print(\"Then open http://localhost:6006 in your browser\")\n",
    "        \n",
    "        # Close TensorBoard writer\n",
    "        self.writer.close()\n",
    "    \n",
    "    def save_checkpoint(self, state, filename):\n",
    "        \"\"\"Save a checkpoint\"\"\"\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        torch.save(state, filename)\n",
    "        print(f\"Checkpoint saved to {filename}\")\n",
    "    \n",
    "    def save_final_statistics(self):\n",
    "        \"\"\"Save final statistics after training\"\"\"\n",
    "        os.makedirs(self.args.save_path, exist_ok=True)\n",
    "        \n",
    "        # Save metrics to CSV\n",
    "        with open(os.path.join(self.args.save_path, 'metrics.csv'), 'w', newline='') as csvfile:\n",
    "            # Extract all keys from all metrics\n",
    "            fieldnames = set()\n",
    "            for metric in self.metrics:\n",
    "                fieldnames.update(k for k in metric.keys() if k != 'strategy_weights')\n",
    "            fieldnames = list(fieldnames) + ['S_U', 'S_D', 'S_C', 'S_B']\n",
    "            \n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for metric in self.metrics:\n",
    "                row = {k: v for k, v in metric.items() if k != 'strategy_weights'}\n",
    "                if 'strategy_weights' in metric:\n",
    "                    for strategy, weight in metric['strategy_weights'].items():\n",
    "                        row[strategy] = weight\n",
    "                writer.writerow(row)\n",
    "        \n",
    "        # Save confusion matrix\n",
    "        _, _, _, _, _, conf_matrix = self.evaluate()\n",
    "        np.savetxt(os.path.join(self.args.save_path, 'confusion_matrix.csv'), conf_matrix, delimiter=\",\")\n",
    "        \n",
    "        # Save final model\n",
    "        torch.save(self.model.state_dict(), os.path.join(self.args.save_path, 'final_model.pth'))\n",
    "        \n",
    "        # Save coreset indices\n",
    "        np.save(os.path.join(self.args.save_path, 'coreset_indices.npy'), self.current_indices)\n",
    "        \n",
    "        # Save weight history\n",
    "        with open(os.path.join(self.args.save_path, 'weight_history.json'), 'w') as f:\n",
    "            json.dump(self.coreset_selector.weight_history, f)\n",
    "        \n",
    "        # Save the complete coreset selector\n",
    "        torch.save(self.coreset_selector, os.path.join(self.args.save_path, 'coreset_selector.pth'))\n",
    "        \n",
    "        # Plot weight evolution\n",
    "        self.plot_weight_evolution()\n",
    "        \n",
    "        # Add final metrics and plots to TensorBoard\n",
    "        # Final coreset distribution by class\n",
    "        class_counts = Counter([self.full_dataset[i][1] for i in self.current_indices])\n",
    "        fig, ax = plt.figure(figsize=(10, 6)), plt.subplot(111)\n",
    "        classes = sorted(class_counts.keys())\n",
    "        counts = [class_counts[c] for c in classes]\n",
    "        ax.bar(classes, counts)\n",
    "        ax.set_xlabel('Class')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title('Final Coreset Class Distribution')\n",
    "        self.writer.add_figure('Coreset/ClassDistribution', fig)\n",
    "        \n",
    "        # Also add final embedding visualization if possible\n",
    "        try:\n",
    "            self.add_embedding_visualization()\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create embedding visualization: {e}\")\n",
    "        \n",
    "        print(f\"Final statistics saved to {self.args.save_path}\")\n",
    "    \n",
    "    def load_checkpoint(self, filename):\n",
    "        \"\"\"Load a checkpoint\"\"\"\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.current_epoch = checkpoint['epoch']\n",
    "        self.current_indices = checkpoint['current_indices']\n",
    "        self.best_accuracy = checkpoint['best_accuracy']\n",
    "        self.coreset_selector.weights = checkpoint['strategy_weights']\n",
    "        self.update_train_loader()\n",
    "        print(f\"Loaded checkpoint from epoch {self.current_epoch}\")\n",
    "    \n",
    "    def plot_weight_evolution(self):\n",
    "        \"\"\"Plot the evolution of strategy weights during training\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        weight_history = self.coreset_selector.weight_history\n",
    "        epochs = list(range(len(weight_history)))\n",
    "        \n",
    "        for strategy in self.coreset_selector.strategies:\n",
    "            weights = [w[strategy] for w in weight_history]\n",
    "            plt.plot(epochs, weights, label=strategy)\n",
    "        \n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Strategy Weight')\n",
    "        plt.title('SPARROW Strategy Weight Evolution')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(self.args.save_path, 'weight_evolution.png'))\n",
    "        plt.close()\n",
    "\n",
    "    def add_embedding_visualization(self):\n",
    "        \"\"\"Add embedding visualization to TensorBoard\"\"\"\n",
    "        # Get feature embeddings for the coreset\n",
    "        feature_extractor = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        feature_extractor.eval()\n",
    "        \n",
    "        coreset_subset = Subset(self.full_dataset, self.current_indices)\n",
    "        coreset_loader = DataLoader(\n",
    "            coreset_subset,\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        all_images = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, targets) in enumerate(coreset_loader):\n",
    "                if i == 0:  # Store only first batch of images to avoid memory issues\n",
    "                    all_images = inputs\n",
    "                \n",
    "                inputs = inputs.to(self.device)\n",
    "                features = feature_extractor(inputs)\n",
    "                features = features.squeeze().cpu()\n",
    "                \n",
    "                all_features.append(features)\n",
    "                all_labels.extend(targets.numpy())\n",
    "        \n",
    "        if all_features:\n",
    "            all_features = torch.cat(all_features, 0)\n",
    "            \n",
    "            # Add embedding visualization\n",
    "            self.writer.add_embedding(\n",
    "                all_features,\n",
    "                metadata=all_labels,\n",
    "                label_img=all_images[:100] if len(all_images) > 0 else None,\n",
    "                global_step=self.args.epochs,\n",
    "                tag='coreset_embeddings'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba27cd61-1058-4e0a-b3cc-cac811d0f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run SPARROW coreset selection\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='SPARROW: Strategic Policy-based Active Re-weighting Workflow')\n",
    "    \n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--dataset', type=str, default='cifar10', choices=['cifar10', 'cifar100'],\n",
    "                      help='dataset to use: cifar10 or cifar100 (default: cifar10)')\n",
    "    \n",
    "    # Training parameters\n",
    "    parser.add_argument('--batch-size', type=int, default=128, \n",
    "                      help='input batch size for training (default: 128)')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                      help='number of epochs to train (default: 200)')\n",
    "    parser.add_argument('--lr', type=float, default=0.001,\n",
    "                      help='learning rate (default: 0.001)')\n",
    "    \n",
    "    # Coreset parameters\n",
    "    parser.add_argument('--max-budget', type=int, default=5000,\n",
    "                      help='maximum coreset size (default: 5000)')\n",
    "    parser.add_argument('--initial-sample-size', type=int, default=1000,\n",
    "                      help='initial coreset size (default: 1000)')\n",
    "    parser.add_argument('--samples-per-epoch', type=int, default=200,\n",
    "                      help='number of samples to add per epoch (default: 200)')\n",
    "    \n",
    "    # System parameters\n",
    "    parser.add_argument('--save-path', type=str, default='./results/sparrow',\n",
    "                      help='path to save results (default: ./results/sparrow)')\n",
    "    parser.add_argument('--resume', type=str, default='',\n",
    "                      help='path to latest checkpoint (default: none)')\n",
    "    parser.add_argument('--workers', type=int, default=3,\n",
    "                      help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--print-freq', type=int, default=10,\n",
    "                      help='print frequency (default: 10)')\n",
    "    parser.add_argument('--seed', type=int, default=42,\n",
    "                      help='random seed (default: 42)')\n",
    "    # Add tensorboard log directory option\n",
    "    parser.add_argument('--tensorboard-dir', type=str, default=None,\n",
    "                      help='tensorboard log directory (default: save_path/tensorboard/timestamp)')\n",
    "    \n",
    "    # Add device selection option\n",
    "    parser.add_argument('--device', type=str, default=None,\n",
    "                      help='device to use (cuda, mps, cpu, or None for auto-detection)')\n",
    "    \n",
    "    args = parser.parse_args([])\n",
    "    \n",
    "    # Set random seed\n",
    "    if args.seed is not None:\n",
    "        torch.manual_seed(args.seed)\n",
    "        np.random.seed(args.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Create save directory\n",
    "    os.makedirs(args.save_path, exist_ok=True)\n",
    "    \n",
    "    # Save command line arguments\n",
    "    with open(os.path.join(args.save_path, 'args.json'), 'w') as f:\n",
    "        json.dump(vars(args), f, indent=4)\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = SPARROWTrainer(args)\n",
    "    \n",
    "    # Load checkpoint if specified\n",
    "    if args.resume:\n",
    "        trainer.load_checkpoint(args.resume)\n",
    "    \n",
    "    # Run training\n",
    "    trainer.run()\n",
    "    \n",
    "    print(\"SPARROW coreset selection completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817ea41-c33b-48d5-a7ad-fb32c37d8868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/tmukherj/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 178MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing with 1000 samples...\n",
      "Scanning dataset for class distribution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing dataset: 100%|██████████| 50000/50000 [00:21<00:00, 2348.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting ~100 samples per class...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting samples by class: 100%|██████████| 10/10 [00:00<00:00, 1437.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1000 initial samples\n",
      "Meta-controller initialized successfully\n",
      "TensorBoard logs will be saved to ./results/sparrow/tensorboard/20250331-181958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 0 [Train]:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0 [Train]:   0%|          | 0/8 [00:00<?, ?it/s, loss=2.6964, acc=10.94%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]:  12%|█▎        | 1/8 [00:00<00:06,  1.03it/s, loss=2.6964, acc=10.94%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]:  12%|█▎        | 1/8 [00:01<00:06,  1.03it/s, loss=2.2895, acc=14.84%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]:  12%|█▎        | 1/8 [00:01<00:06,  1.03it/s, loss=2.3372, acc=16.93%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]:  38%|███▊      | 3/8 [00:01<00:01,  3.34it/s, loss=2.3372, acc=16.93%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]:  38%|███▊      | 3/8 [00:01<00:01,  3.34it/s, loss=2.1491, acc=18.95%, lr=0.001000]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 [0/1000 (0%)] Loss: 2.696437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 [Train]:  38%|███▊      | 3/8 [00:01<00:01,  3.34it/s, loss=2.2089, acc=20.31%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]:  38%|███▊      | 3/8 [00:01<00:01,  3.34it/s, loss=1.9077, acc=21.35%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]:  75%|███████▌  | 6/8 [00:01<00:00,  6.98it/s, loss=1.9077, acc=21.35%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]:  75%|███████▌  | 6/8 [00:01<00:00,  6.98it/s, loss=2.1394, acc=22.77%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]:  75%|███████▌  | 6/8 [00:01<00:00,  6.98it/s, loss=2.0494, acc=23.80%, lr=0.001000]\u001b[A\n",
      "Epoch 0 [Train]: 100%|██████████| 8/8 [00:01<00:00,  9.15it/s, loss=2.0494, acc=23.80%, lr=0.001000]\u001b[A\n",
      "                                                                                                    \u001b[A\n",
      "Evaluation:   0%|          | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluation:   0%|          | 0/79 [00:00<?, ?it/s, loss=1.8229, acc=39.84%]\u001b[A\n",
      "Evaluation:   1%|▏         | 1/79 [00:00<00:48,  1.60it/s, loss=1.8229, acc=39.84%]\u001b[A\n",
      "Evaluation:   1%|▏         | 1/79 [00:00<00:48,  1.60it/s, loss=2.1062, acc=37.11%]\u001b[A\n",
      "Evaluation:   1%|▏         | 1/79 [00:00<00:48,  1.60it/s, loss=1.8777, acc=36.98%]\u001b[A\n",
      "Evaluation:   4%|▍         | 3/79 [00:00<00:16,  4.55it/s, loss=1.8777, acc=36.98%]\u001b[A\n",
      "Evaluation:   4%|▍         | 3/79 [00:00<00:16,  4.55it/s, loss=2.0605, acc=35.55%]\u001b[A\n",
      "Evaluation:   4%|▍         | 3/79 [00:00<00:16,  4.55it/s, loss=1.9144, acc=35.16%]\u001b[A\n",
      "Evaluation:   4%|▍         | 3/79 [00:00<00:16,  4.55it/s, loss=1.8699, acc=35.03%]\u001b[A\n",
      "Evaluation:   4%|▍         | 3/79 [00:00<00:16,  4.55it/s, loss=1.7750, acc=35.60%]\u001b[A\n",
      "Evaluation:   4%|▍         | 3/79 [00:00<00:16,  4.55it/s, loss=1.8012, acc=36.04%]\u001b[A\n",
      "Evaluation:  10%|█         | 8/79 [00:00<00:05, 13.08it/s, loss=1.8012, acc=36.04%]\u001b[A\n",
      "Evaluation:  10%|█         | 8/79 [00:00<00:05, 13.08it/s, loss=2.2098, acc=34.46%]\u001b[A\n",
      "Evaluation:  10%|█         | 8/79 [00:00<00:05, 13.08it/s, loss=1.8927, acc=34.30%]\u001b[A\n",
      "Evaluation:  10%|█         | 8/79 [00:00<00:05, 13.08it/s, loss=1.9096, acc=34.52%]\u001b[A\n",
      "Evaluation:  10%|█         | 8/79 [00:01<00:05, 13.08it/s, loss=1.9252, acc=35.22%]\u001b[A\n",
      "Evaluation:  15%|█▌        | 12/79 [00:01<00:03, 17.95it/s, loss=1.9252, acc=35.22%]\u001b[A\n",
      "Evaluation:  15%|█▌        | 12/79 [00:01<00:03, 17.95it/s, loss=1.9831, acc=34.56%]\u001b[A\n",
      "Evaluation:  15%|█▌        | 12/79 [00:01<00:03, 17.95it/s, loss=2.0080, acc=34.71%]\u001b[A\n",
      "Evaluation:  15%|█▌        | 12/79 [00:01<00:03, 17.95it/s, loss=1.8021, acc=34.95%]\u001b[A\n",
      "Evaluation:  15%|█▌        | 12/79 [00:01<00:03, 17.95it/s, loss=1.9491, acc=34.86%]\u001b[A\n",
      "Evaluation:  20%|██        | 16/79 [00:01<00:02, 22.15it/s, loss=1.9491, acc=34.86%]\u001b[A\n",
      "Evaluation:  20%|██        | 16/79 [00:01<00:02, 22.15it/s, loss=1.8112, acc=34.93%]\u001b[A\n",
      "Evaluation:  20%|██        | 16/79 [00:01<00:02, 22.15it/s, loss=2.1904, acc=34.29%]\u001b[A\n",
      "Evaluation:  20%|██        | 16/79 [00:01<00:02, 22.15it/s, loss=1.8349, acc=34.38%]\u001b[A\n",
      "Evaluation:  20%|██        | 16/79 [00:01<00:02, 22.15it/s, loss=2.0993, acc=34.18%]\u001b[A\n",
      "Evaluation:  25%|██▌       | 20/79 [00:01<00:02, 23.64it/s, loss=2.0993, acc=34.18%]\u001b[A\n",
      "Evaluation:  25%|██▌       | 20/79 [00:01<00:02, 23.64it/s, loss=1.8113, acc=34.08%]\u001b[A\n",
      "Evaluation:  25%|██▌       | 20/79 [00:01<00:02, 23.64it/s, loss=1.9988, acc=34.02%]\u001b[A\n",
      "Evaluation:  25%|██▌       | 20/79 [00:01<00:02, 23.64it/s, loss=1.9033, acc=33.93%]\u001b[A\n",
      "Evaluation:  25%|██▌       | 20/79 [00:01<00:02, 23.64it/s, loss=1.8949, acc=34.11%]\u001b[A\n",
      "Evaluation:  25%|██▌       | 20/79 [00:01<00:02, 23.64it/s, loss=1.6457, acc=34.50%]\u001b[A\n",
      "Evaluation:  32%|███▏      | 25/79 [00:01<00:01, 28.41it/s, loss=1.6457, acc=34.50%]\u001b[A\n",
      "Evaluation:  32%|███▏      | 25/79 [00:01<00:01, 28.41it/s, loss=1.9516, acc=34.53%]\u001b[A\n",
      "Evaluation:  32%|███▏      | 25/79 [00:01<00:01, 28.41it/s, loss=1.9544, acc=34.55%]\u001b[A\n",
      "Evaluation:  32%|███▏      | 25/79 [00:01<00:01, 28.41it/s, loss=1.9169, acc=34.18%]\u001b[A\n",
      "Evaluation:  32%|███▏      | 25/79 [00:01<00:01, 28.41it/s, loss=1.9946, acc=33.97%]\u001b[A\n",
      "Evaluation:  37%|███▋      | 29/79 [00:01<00:01, 30.47it/s, loss=1.9946, acc=33.97%]\u001b[A\n",
      "Evaluation:  37%|███▋      | 29/79 [00:01<00:01, 30.47it/s, loss=1.9547, acc=34.04%]\u001b[A\n",
      "Evaluation:  37%|███▋      | 29/79 [00:01<00:01, 30.47it/s, loss=1.7369, acc=34.17%]\u001b[A\n",
      "Evaluation:  37%|███▋      | 29/79 [00:01<00:01, 30.47it/s, loss=1.8513, acc=34.11%]\u001b[A\n",
      "Evaluation:  37%|███▋      | 29/79 [00:01<00:01, 30.47it/s, loss=2.0628, acc=34.07%]\u001b[A\n",
      "Evaluation:  42%|████▏     | 33/79 [00:01<00:01, 31.45it/s, loss=2.0628, acc=34.07%]\u001b[A\n",
      "Evaluation:  42%|████▏     | 33/79 [00:01<00:01, 31.45it/s, loss=1.9272, acc=33.96%]\u001b[A\n",
      "Evaluation:  42%|████▏     | 33/79 [00:01<00:01, 31.45it/s, loss=1.8427, acc=34.15%]\u001b[A\n",
      "Evaluation:  42%|████▏     | 33/79 [00:01<00:01, 31.45it/s, loss=1.8851, acc=34.09%]\u001b[A\n",
      "Evaluation:  42%|████▏     | 33/79 [00:01<00:01, 31.45it/s, loss=1.9232, acc=34.21%]\u001b[A\n",
      "Evaluation:  42%|████▏     | 33/79 [00:01<00:01, 31.45it/s, loss=1.9773, acc=34.33%]\u001b[A\n",
      "Evaluation:  48%|████▊     | 38/79 [00:01<00:01, 34.90it/s, loss=1.9773, acc=34.33%]\u001b[A\n",
      "Evaluation:  48%|████▊     | 38/79 [00:01<00:01, 34.90it/s, loss=1.8300, acc=34.27%]\u001b[A\n",
      "Evaluation:  48%|████▊     | 38/79 [00:01<00:01, 34.90it/s, loss=1.9345, acc=34.28%]\u001b[A\n",
      "Evaluation:  48%|████▊     | 38/79 [00:01<00:01, 34.90it/s, loss=2.0706, acc=34.18%]\u001b[A\n",
      "Evaluation:  48%|████▊     | 38/79 [00:01<00:01, 34.90it/s, loss=2.0871, acc=34.04%]\u001b[A\n",
      "Evaluation:  48%|████▊     | 38/79 [00:01<00:01, 34.90it/s, loss=1.9144, acc=34.08%]\u001b[A\n",
      "Evaluation:  54%|█████▍    | 43/79 [00:01<00:00, 37.60it/s, loss=1.9144, acc=34.08%]\u001b[A\n",
      "Evaluation:  54%|█████▍    | 43/79 [00:01<00:00, 37.60it/s, loss=2.2147, acc=33.93%]\u001b[A\n",
      "Evaluation:  54%|█████▍    | 43/79 [00:01<00:00, 37.60it/s, loss=1.9715, acc=33.92%]\u001b[A\n",
      "Evaluation:  54%|█████▍    | 43/79 [00:01<00:00, 37.60it/s, loss=1.9722, acc=33.93%]\u001b[A\n",
      "Evaluation:  54%|█████▍    | 43/79 [00:01<00:00, 37.60it/s, loss=1.8352, acc=34.03%]\u001b[A\n",
      "Evaluation:  54%|█████▍    | 43/79 [00:01<00:00, 37.60it/s, loss=2.0260, acc=34.00%]\u001b[A\n",
      "Evaluation:  61%|██████    | 48/79 [00:01<00:00, 38.54it/s, loss=2.0260, acc=34.00%]\u001b[A\n",
      "Evaluation:  61%|██████    | 48/79 [00:01<00:00, 38.54it/s, loss=1.8912, acc=34.01%]\u001b[A\n",
      "Evaluation:  61%|██████    | 48/79 [00:02<00:00, 38.54it/s, loss=1.8504, acc=34.00%]\u001b[A\n",
      "Evaluation:  61%|██████    | 48/79 [00:02<00:00, 38.54it/s, loss=2.0526, acc=33.92%]\u001b[A\n",
      "Evaluation:  61%|██████    | 48/79 [00:02<00:00, 38.54it/s, loss=1.9548, acc=33.98%]\u001b[A\n",
      "Evaluation:  66%|██████▌   | 52/79 [00:02<00:00, 38.00it/s, loss=1.9548, acc=33.98%]\u001b[A\n",
      "Evaluation:  66%|██████▌   | 52/79 [00:02<00:00, 38.00it/s, loss=2.0934, acc=33.95%]\u001b[A\n",
      "Evaluation:  66%|██████▌   | 52/79 [00:02<00:00, 38.00it/s, loss=1.9869, acc=33.85%]\u001b[A\n",
      "Evaluation:  66%|██████▌   | 52/79 [00:02<00:00, 38.00it/s, loss=1.9401, acc=33.85%]\u001b[A\n",
      "Evaluation:  66%|██████▌   | 52/79 [00:02<00:00, 38.00it/s, loss=1.8040, acc=34.03%]\u001b[A\n",
      "Evaluation:  71%|███████   | 56/79 [00:02<00:00, 33.28it/s, loss=1.8040, acc=34.03%]\u001b[A\n",
      "Evaluation:  71%|███████   | 56/79 [00:02<00:00, 33.28it/s, loss=1.9334, acc=34.06%]\u001b[A\n",
      "Evaluation:  71%|███████   | 56/79 [00:02<00:00, 33.28it/s, loss=1.9132, acc=33.96%]\u001b[A\n",
      "Evaluation:  71%|███████   | 56/79 [00:02<00:00, 33.28it/s, loss=1.9150, acc=33.90%]\u001b[A\n",
      "Evaluation:  71%|███████   | 56/79 [00:02<00:00, 33.28it/s, loss=1.8946, acc=33.88%]\u001b[A\n",
      "Evaluation:  76%|███████▌  | 60/79 [00:02<00:00, 34.87it/s, loss=1.8946, acc=33.88%]\u001b[A\n",
      "Evaluation:  76%|███████▌  | 60/79 [00:02<00:00, 34.87it/s, loss=1.8841, acc=33.91%]\u001b[A\n",
      "Evaluation:  76%|███████▌  | 60/79 [00:02<00:00, 34.87it/s, loss=1.9582, acc=33.85%]\u001b[A\n",
      "Evaluation:  76%|███████▌  | 60/79 [00:02<00:00, 34.87it/s, loss=1.8901, acc=33.83%]\u001b[A\n",
      "Evaluation:  76%|███████▌  | 60/79 [00:02<00:00, 34.87it/s, loss=2.0250, acc=33.84%]\u001b[A\n",
      "Evaluation:  81%|████████  | 64/79 [00:02<00:00, 35.66it/s, loss=2.0250, acc=33.84%]\u001b[A\n",
      "Evaluation:  81%|████████  | 64/79 [00:02<00:00, 35.66it/s, loss=2.0622, acc=33.71%]\u001b[A\n",
      "Evaluation:  81%|████████  | 64/79 [00:02<00:00, 35.66it/s, loss=1.9803, acc=33.63%]\u001b[A\n",
      "Evaluation:  81%|████████  | 64/79 [00:02<00:00, 35.66it/s, loss=1.9289, acc=33.57%]\u001b[A\n",
      "Evaluation:  81%|████████  | 64/79 [00:02<00:00, 35.66it/s, loss=1.9849, acc=33.50%]\u001b[A\n",
      "Evaluation:  81%|████████  | 64/79 [00:02<00:00, 35.66it/s, loss=1.8634, acc=33.53%]\u001b[A\n",
      "Evaluation:  81%|████████  | 64/79 [00:02<00:00, 35.66it/s, loss=2.0023, acc=33.53%]\u001b[A\n",
      "Evaluation:  89%|████████▊ | 70/79 [00:02<00:00, 39.18it/s, loss=2.0023, acc=33.53%]\u001b[A\n",
      "Evaluation:  89%|████████▊ | 70/79 [00:02<00:00, 39.18it/s, loss=2.0281, acc=33.45%]\u001b[A\n",
      "Evaluation:  89%|████████▊ | 70/79 [00:02<00:00, 39.18it/s, loss=1.7176, acc=33.59%]\u001b[A\n",
      "Evaluation:  89%|████████▊ | 70/79 [00:02<00:00, 39.18it/s, loss=1.8545, acc=33.66%]\u001b[A\n",
      "Evaluation:  89%|████████▊ | 70/79 [00:02<00:00, 39.18it/s, loss=1.9961, acc=33.64%]\u001b[A\n",
      "Evaluation:  89%|████████▊ | 70/79 [00:02<00:00, 39.18it/s, loss=1.8096, acc=33.69%]\u001b[A\n",
      "Evaluation:  95%|█████████▍| 75/79 [00:02<00:00, 41.59it/s, loss=1.8096, acc=33.69%]\u001b[A\n",
      "Evaluation:  95%|█████████▍| 75/79 [00:02<00:00, 41.59it/s, loss=2.0144, acc=33.74%]\u001b[A\n",
      "Evaluation:  95%|█████████▍| 75/79 [00:02<00:00, 41.59it/s, loss=2.0598, acc=33.65%]\u001b[A\n",
      "Evaluation:  95%|█████████▍| 75/79 [00:02<00:00, 41.59it/s, loss=1.9919, acc=33.66%]\u001b[A\n",
      "Evaluation:  95%|█████████▍| 75/79 [00:02<00:00, 41.59it/s, loss=1.6808, acc=33.68%]\u001b[A\n",
      "                                                                                    \u001b[A/tmp/ipykernel_557/2118008505.py:228: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + [str(i) for i in range(10)])\n",
      "/tmp/ipykernel_557/2118008505.py:229: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + [str(i) for i in range(10)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updating strategy weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing training loss:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Computing training loss:   0%|          | 0/8 [00:00<?, ?it/s, loss=1.8093]\u001b[A\n",
      "Computing training loss:  12%|█▎        | 1/8 [00:00<00:04,  1.70it/s, loss=1.8093]\u001b[A\n",
      "Computing training loss:  12%|█▎        | 1/8 [00:00<00:04,  1.70it/s, loss=1.7090]\u001b[A\n",
      "Computing training loss:  12%|█▎        | 1/8 [00:00<00:04,  1.70it/s, loss=1.6269]\u001b[A\n",
      "Computing training loss:  12%|█▎        | 1/8 [00:00<00:04,  1.70it/s, loss=1.7601]\u001b[A\n",
      "Computing training loss:  12%|█▎        | 1/8 [00:00<00:04,  1.70it/s, loss=1.8053]\u001b[A\n",
      "Computing training loss:  12%|█▎        | 1/8 [00:00<00:04,  1.70it/s, loss=1.6144]\u001b[A\n",
      "Computing training loss:  12%|█▎        | 1/8 [00:00<00:04,  1.70it/s, loss=1.7553]\u001b[A\n",
      "Computing training loss:  88%|████████▊ | 7/8 [00:00<00:00, 13.01it/s, loss=1.7553]\u001b[A\n",
      "Computing training loss:  88%|████████▊ | 7/8 [00:00<00:00, 13.01it/s, loss=1.6460]\u001b[A\n",
      "                                                                                   \u001b[A\n",
      "Computing strategy scores:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Computing strategy scores:   0%|          | 0/4 [00:00<?, ?it/s, stage=uncertainty]\u001b[A/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\n",
      "\n",
      "Computing uncertainty scores:   0%|          | 0/391 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   0%|          | 0/391 [00:00<?, ?it/s, processed=128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   0%|          | 1/391 [00:00<05:47,  1.12it/s, processed=128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   0%|          | 1/391 [00:00<05:47,  1.12it/s, processed=256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   0%|          | 1/391 [00:00<05:47,  1.12it/s, processed=384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   0%|          | 1/391 [00:01<05:47,  1.12it/s, processed=512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   1%|          | 4/391 [00:01<01:17,  4.99it/s, processed=512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   1%|          | 4/391 [00:01<01:17,  4.99it/s, processed=640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   1%|          | 4/391 [00:01<01:17,  4.99it/s, processed=768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   1%|          | 4/391 [00:01<01:17,  4.99it/s, processed=896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   1%|          | 4/391 [00:01<01:17,  4.99it/s, processed=1024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   2%|▏         | 8/391 [00:01<00:37, 10.09it/s, processed=1024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   2%|▏         | 8/391 [00:01<00:37, 10.09it/s, processed=1152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   2%|▏         | 8/391 [00:01<00:37, 10.09it/s, processed=1280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   2%|▏         | 8/391 [00:01<00:37, 10.09it/s, processed=1408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   2%|▏         | 8/391 [00:01<00:37, 10.09it/s, processed=1536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   3%|▎         | 12/391 [00:01<00:24, 15.19it/s, processed=1536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   3%|▎         | 12/391 [00:01<00:24, 15.19it/s, processed=1664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   3%|▎         | 12/391 [00:01<00:24, 15.19it/s, processed=1792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   3%|▎         | 12/391 [00:01<00:24, 15.19it/s, processed=1920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   4%|▍         | 15/391 [00:01<00:20, 18.11it/s, processed=1920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   4%|▍         | 15/391 [00:01<00:20, 18.11it/s, processed=2048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   4%|▍         | 15/391 [00:01<00:20, 18.11it/s, processed=2176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   4%|▍         | 15/391 [00:01<00:20, 18.11it/s, processed=2304/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   4%|▍         | 15/391 [00:01<00:20, 18.11it/s, processed=2432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   5%|▍         | 19/391 [00:01<00:16, 22.07it/s, processed=2432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   5%|▍         | 19/391 [00:01<00:16, 22.07it/s, processed=2560/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   5%|▍         | 19/391 [00:01<00:16, 22.07it/s, processed=2688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   5%|▍         | 19/391 [00:01<00:16, 22.07it/s, processed=2816/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   5%|▍         | 19/391 [00:01<00:16, 22.07it/s, processed=2944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   6%|▌         | 23/391 [00:01<00:14, 25.66it/s, processed=2944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   6%|▌         | 23/391 [00:01<00:14, 25.66it/s, processed=3072/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   6%|▌         | 23/391 [00:01<00:14, 25.66it/s, processed=3200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   6%|▌         | 23/391 [00:01<00:14, 25.66it/s, processed=3328/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   6%|▌         | 23/391 [00:01<00:14, 25.66it/s, processed=3456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   7%|▋         | 27/391 [00:01<00:15, 23.99it/s, processed=3456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   7%|▋         | 27/391 [00:01<00:15, 23.99it/s, processed=3584/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   7%|▋         | 27/391 [00:01<00:15, 23.99it/s, processed=3712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   7%|▋         | 27/391 [00:01<00:15, 23.99it/s, processed=3840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   8%|▊         | 30/391 [00:01<00:14, 24.72it/s, processed=3840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   8%|▊         | 30/391 [00:01<00:14, 24.72it/s, processed=3968/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   8%|▊         | 30/391 [00:02<00:14, 24.72it/s, processed=4096/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   8%|▊         | 30/391 [00:02<00:14, 24.72it/s, processed=4224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   8%|▊         | 33/391 [00:02<00:17, 19.92it/s, processed=4224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   8%|▊         | 33/391 [00:02<00:17, 19.92it/s, processed=4352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   8%|▊         | 33/391 [00:02<00:17, 19.92it/s, processed=4480/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   8%|▊         | 33/391 [00:02<00:17, 19.92it/s, processed=4608/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   8%|▊         | 33/391 [00:02<00:17, 19.92it/s, processed=4736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   9%|▉         | 37/391 [00:02<00:14, 23.72it/s, processed=4736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   9%|▉         | 37/391 [00:02<00:14, 23.72it/s, processed=4864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   9%|▉         | 37/391 [00:02<00:14, 23.72it/s, processed=4992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   9%|▉         | 37/391 [00:02<00:14, 23.72it/s, processed=5120/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:   9%|▉         | 37/391 [00:02<00:14, 23.72it/s, processed=5248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  10%|█         | 41/391 [00:02<00:13, 26.30it/s, processed=5248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  10%|█         | 41/391 [00:02<00:13, 26.30it/s, processed=5376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  10%|█         | 41/391 [00:02<00:13, 26.30it/s, processed=5504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  10%|█         | 41/391 [00:02<00:13, 26.30it/s, processed=5632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  11%|█▏        | 44/391 [00:02<00:13, 26.22it/s, processed=5632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  11%|█▏        | 44/391 [00:02<00:13, 26.22it/s, processed=5760/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  11%|█▏        | 44/391 [00:02<00:13, 26.22it/s, processed=5888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  11%|█▏        | 44/391 [00:02<00:13, 26.22it/s, processed=6016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  11%|█▏        | 44/391 [00:02<00:13, 26.22it/s, processed=6144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  12%|█▏        | 48/391 [00:02<00:11, 29.54it/s, processed=6144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  12%|█▏        | 48/391 [00:02<00:11, 29.54it/s, processed=6272/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  12%|█▏        | 48/391 [00:02<00:11, 29.54it/s, processed=6400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  12%|█▏        | 48/391 [00:02<00:11, 29.54it/s, processed=6528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  12%|█▏        | 48/391 [00:02<00:11, 29.54it/s, processed=6656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  13%|█▎        | 52/391 [00:02<00:11, 30.78it/s, processed=6656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  13%|█▎        | 52/391 [00:02<00:11, 30.78it/s, processed=6784/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  13%|█▎        | 52/391 [00:02<00:11, 30.78it/s, processed=6912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  13%|█▎        | 52/391 [00:02<00:11, 30.78it/s, processed=7040/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  13%|█▎        | 52/391 [00:02<00:11, 30.78it/s, processed=7168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  14%|█▍        | 56/391 [00:02<00:11, 30.45it/s, processed=7168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  14%|█▍        | 56/391 [00:02<00:11, 30.45it/s, processed=7296/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  14%|█▍        | 56/391 [00:02<00:11, 30.45it/s, processed=7424/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  14%|█▍        | 56/391 [00:02<00:11, 30.45it/s, processed=7552/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  14%|█▍        | 56/391 [00:02<00:11, 30.45it/s, processed=7680/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  15%|█▌        | 60/391 [00:02<00:11, 28.48it/s, processed=7680/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  15%|█▌        | 60/391 [00:02<00:11, 28.48it/s, processed=7808/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  15%|█▌        | 60/391 [00:03<00:11, 28.48it/s, processed=7936/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  15%|█▌        | 60/391 [00:03<00:11, 28.48it/s, processed=8064/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  15%|█▌        | 60/391 [00:03<00:11, 28.48it/s, processed=8192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  16%|█▋        | 64/391 [00:03<00:10, 31.05it/s, processed=8192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  16%|█▋        | 64/391 [00:03<00:10, 31.05it/s, processed=8320/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  16%|█▋        | 64/391 [00:03<00:10, 31.05it/s, processed=8448/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  16%|█▋        | 64/391 [00:03<00:10, 31.05it/s, processed=8576/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  16%|█▋        | 64/391 [00:03<00:10, 31.05it/s, processed=8704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  17%|█▋        | 68/391 [00:03<00:09, 33.02it/s, processed=8704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  17%|█▋        | 68/391 [00:03<00:09, 33.02it/s, processed=8832/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  17%|█▋        | 68/391 [00:03<00:09, 33.02it/s, processed=8960/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  17%|█▋        | 68/391 [00:03<00:09, 33.02it/s, processed=9088/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  17%|█▋        | 68/391 [00:03<00:09, 33.02it/s, processed=9216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  18%|█▊        | 72/391 [00:03<00:09, 34.07it/s, processed=9216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  18%|█▊        | 72/391 [00:03<00:09, 34.07it/s, processed=9344/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  18%|█▊        | 72/391 [00:03<00:09, 34.07it/s, processed=9472/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  18%|█▊        | 72/391 [00:03<00:09, 34.07it/s, processed=9600/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  18%|█▊        | 72/391 [00:03<00:09, 34.07it/s, processed=9728/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  19%|█▉        | 76/391 [00:03<00:09, 33.60it/s, processed=9728/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  19%|█▉        | 76/391 [00:03<00:09, 33.60it/s, processed=9856/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  19%|█▉        | 76/391 [00:03<00:09, 33.60it/s, processed=9984/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  19%|█▉        | 76/391 [00:03<00:09, 33.60it/s, processed=10112/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  19%|█▉        | 76/391 [00:03<00:09, 33.60it/s, processed=10240/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  20%|██        | 80/391 [00:03<00:09, 31.50it/s, processed=10240/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  20%|██        | 80/391 [00:03<00:09, 31.50it/s, processed=10368/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  20%|██        | 80/391 [00:03<00:09, 31.50it/s, processed=10496/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  20%|██        | 80/391 [00:03<00:09, 31.50it/s, processed=10624/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  20%|██        | 80/391 [00:03<00:09, 31.50it/s, processed=10752/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  21%|██▏       | 84/391 [00:03<00:09, 31.74it/s, processed=10752/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  21%|██▏       | 84/391 [00:03<00:09, 31.74it/s, processed=10880/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  21%|██▏       | 84/391 [00:03<00:09, 31.74it/s, processed=11008/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  21%|██▏       | 84/391 [00:03<00:09, 31.74it/s, processed=11136/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  21%|██▏       | 84/391 [00:03<00:09, 31.74it/s, processed=11264/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  23%|██▎       | 88/391 [00:03<00:09, 33.50it/s, processed=11264/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  23%|██▎       | 88/391 [00:03<00:09, 33.50it/s, processed=11392/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  23%|██▎       | 88/391 [00:03<00:09, 33.50it/s, processed=11520/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  23%|██▎       | 88/391 [00:03<00:09, 33.50it/s, processed=11648/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  23%|██▎       | 88/391 [00:03<00:09, 33.50it/s, processed=11776/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  24%|██▎       | 92/391 [00:03<00:08, 34.25it/s, processed=11776/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  24%|██▎       | 92/391 [00:03<00:08, 34.25it/s, processed=11904/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  24%|██▎       | 92/391 [00:03<00:08, 34.25it/s, processed=12032/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  24%|██▎       | 92/391 [00:04<00:08, 34.25it/s, processed=12160/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  24%|██▎       | 92/391 [00:04<00:08, 34.25it/s, processed=12288/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  25%|██▍       | 96/391 [00:04<00:10, 28.99it/s, processed=12288/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  25%|██▍       | 96/391 [00:04<00:10, 28.99it/s, processed=12416/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  25%|██▍       | 96/391 [00:04<00:10, 28.99it/s, processed=12544/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  25%|██▍       | 96/391 [00:04<00:10, 28.99it/s, processed=12672/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  25%|██▍       | 96/391 [00:04<00:10, 28.99it/s, processed=12800/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  26%|██▌       | 100/391 [00:04<00:10, 29.00it/s, processed=12800/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  26%|██▌       | 100/391 [00:04<00:10, 29.00it/s, processed=12928/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  26%|██▌       | 100/391 [00:04<00:10, 29.00it/s, processed=13056/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  26%|██▌       | 100/391 [00:04<00:10, 29.00it/s, processed=13184/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  26%|██▌       | 100/391 [00:04<00:10, 29.00it/s, processed=13312/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  26%|██▌       | 100/391 [00:04<00:10, 29.00it/s, processed=13440/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  27%|██▋       | 105/391 [00:04<00:08, 33.06it/s, processed=13440/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  27%|██▋       | 105/391 [00:04<00:08, 33.06it/s, processed=13568/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  27%|██▋       | 105/391 [00:04<00:08, 33.06it/s, processed=13696/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  27%|██▋       | 105/391 [00:04<00:08, 33.06it/s, processed=13824/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  27%|██▋       | 105/391 [00:04<00:08, 33.06it/s, processed=13952/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  28%|██▊       | 109/391 [00:04<00:09, 28.63it/s, processed=13952/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  28%|██▊       | 109/391 [00:04<00:09, 28.63it/s, processed=14080/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  28%|██▊       | 109/391 [00:04<00:09, 28.63it/s, processed=14208/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  28%|██▊       | 109/391 [00:04<00:09, 28.63it/s, processed=14336/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  28%|██▊       | 109/391 [00:04<00:09, 28.63it/s, processed=14464/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  29%|██▉       | 113/391 [00:04<00:09, 29.78it/s, processed=14464/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  29%|██▉       | 113/391 [00:04<00:09, 29.78it/s, processed=14592/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  29%|██▉       | 113/391 [00:04<00:09, 29.78it/s, processed=14720/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  29%|██▉       | 113/391 [00:04<00:09, 29.78it/s, processed=14848/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  29%|██▉       | 113/391 [00:04<00:09, 29.78it/s, processed=14976/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  30%|██▉       | 117/391 [00:04<00:09, 28.82it/s, processed=14976/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  30%|██▉       | 117/391 [00:04<00:09, 28.82it/s, processed=15104/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  30%|██▉       | 117/391 [00:04<00:09, 28.82it/s, processed=15232/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  30%|██▉       | 117/391 [00:04<00:09, 28.82it/s, processed=15360/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  30%|██▉       | 117/391 [00:04<00:09, 28.82it/s, processed=15488/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  31%|███       | 121/391 [00:04<00:09, 28.95it/s, processed=15488/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  31%|███       | 121/391 [00:04<00:09, 28.95it/s, processed=15616/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  31%|███       | 121/391 [00:05<00:09, 28.95it/s, processed=15744/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  31%|███       | 121/391 [00:05<00:09, 28.95it/s, processed=15872/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  32%|███▏      | 124/391 [00:05<00:09, 27.73it/s, processed=15872/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  32%|███▏      | 124/391 [00:05<00:09, 27.73it/s, processed=16000/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  32%|███▏      | 124/391 [00:05<00:09, 27.73it/s, processed=16128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  32%|███▏      | 124/391 [00:05<00:09, 27.73it/s, processed=16256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  32%|███▏      | 127/391 [00:05<00:11, 22.88it/s, processed=16256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  32%|███▏      | 127/391 [00:05<00:11, 22.88it/s, processed=16384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  32%|███▏      | 127/391 [00:05<00:11, 22.88it/s, processed=16512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  32%|███▏      | 127/391 [00:05<00:11, 22.88it/s, processed=16640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  33%|███▎      | 130/391 [00:05<00:11, 21.83it/s, processed=16640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  33%|███▎      | 130/391 [00:05<00:11, 21.83it/s, processed=16768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  33%|███▎      | 130/391 [00:05<00:11, 21.83it/s, processed=16896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  33%|███▎      | 130/391 [00:05<00:11, 21.83it/s, processed=17024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  33%|███▎      | 130/391 [00:05<00:11, 21.83it/s, processed=17152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  34%|███▍      | 134/391 [00:05<00:10, 24.38it/s, processed=17152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  34%|███▍      | 134/391 [00:05<00:10, 24.38it/s, processed=17280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  34%|███▍      | 134/391 [00:05<00:10, 24.38it/s, processed=17408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  34%|███▍      | 134/391 [00:05<00:10, 24.38it/s, processed=17536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  35%|███▌      | 137/391 [00:05<00:10, 25.39it/s, processed=17536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  35%|███▌      | 137/391 [00:05<00:10, 25.39it/s, processed=17664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  35%|███▌      | 137/391 [00:05<00:10, 25.39it/s, processed=17792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  35%|███▌      | 137/391 [00:05<00:10, 25.39it/s, processed=17920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  35%|███▌      | 137/391 [00:05<00:10, 25.39it/s, processed=18048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  36%|███▌      | 141/391 [00:05<00:09, 25.42it/s, processed=18048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  36%|███▌      | 141/391 [00:05<00:09, 25.42it/s, processed=18176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  36%|███▌      | 141/391 [00:05<00:09, 25.42it/s, processed=18304/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  36%|███▌      | 141/391 [00:05<00:09, 25.42it/s, processed=18432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  36%|███▌      | 141/391 [00:05<00:09, 25.42it/s, processed=18560/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  36%|███▌      | 141/391 [00:05<00:09, 25.42it/s, processed=18688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  37%|███▋      | 146/391 [00:05<00:07, 30.66it/s, processed=18688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  37%|███▋      | 146/391 [00:05<00:07, 30.66it/s, processed=18816/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  37%|███▋      | 146/391 [00:05<00:07, 30.66it/s, processed=18944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  37%|███▋      | 146/391 [00:05<00:07, 30.66it/s, processed=19072/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  37%|███▋      | 146/391 [00:06<00:07, 30.66it/s, processed=19200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  38%|███▊      | 150/391 [00:06<00:08, 28.48it/s, processed=19200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  38%|███▊      | 150/391 [00:06<00:08, 28.48it/s, processed=19328/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  38%|███▊      | 150/391 [00:06<00:08, 28.48it/s, processed=19456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  38%|███▊      | 150/391 [00:06<00:08, 28.48it/s, processed=19584/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  38%|███▊      | 150/391 [00:06<00:08, 28.48it/s, processed=19712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  39%|███▉      | 154/391 [00:06<00:07, 30.31it/s, processed=19712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  39%|███▉      | 154/391 [00:06<00:07, 30.31it/s, processed=19840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  39%|███▉      | 154/391 [00:06<00:07, 30.31it/s, processed=19968/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  39%|███▉      | 154/391 [00:06<00:07, 30.31it/s, processed=20096/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  39%|███▉      | 154/391 [00:06<00:07, 30.31it/s, processed=20224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  40%|████      | 158/391 [00:06<00:08, 28.92it/s, processed=20224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  40%|████      | 158/391 [00:06<00:08, 28.92it/s, processed=20352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  40%|████      | 158/391 [00:06<00:08, 28.92it/s, processed=20480/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  40%|████      | 158/391 [00:06<00:08, 28.92it/s, processed=20608/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  40%|████      | 158/391 [00:06<00:08, 28.92it/s, processed=20736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  40%|████      | 158/391 [00:06<00:08, 28.92it/s, processed=20864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  42%|████▏     | 163/391 [00:06<00:07, 30.80it/s, processed=20864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  42%|████▏     | 163/391 [00:06<00:07, 30.80it/s, processed=20992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  42%|████▏     | 163/391 [00:06<00:07, 30.80it/s, processed=21120/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  42%|████▏     | 163/391 [00:06<00:07, 30.80it/s, processed=21248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  42%|████▏     | 163/391 [00:06<00:07, 30.80it/s, processed=21376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  43%|████▎     | 167/391 [00:06<00:07, 30.93it/s, processed=21376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  43%|████▎     | 167/391 [00:06<00:07, 30.93it/s, processed=21504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  43%|████▎     | 167/391 [00:06<00:07, 30.93it/s, processed=21632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  43%|████▎     | 167/391 [00:06<00:07, 30.93it/s, processed=21760/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  43%|████▎     | 167/391 [00:06<00:07, 30.93it/s, processed=21888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  44%|████▎     | 171/391 [00:06<00:06, 33.01it/s, processed=21888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  44%|████▎     | 171/391 [00:06<00:06, 33.01it/s, processed=22016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  44%|████▎     | 171/391 [00:06<00:06, 33.01it/s, processed=22144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  44%|████▎     | 171/391 [00:06<00:06, 33.01it/s, processed=22272/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  44%|████▎     | 171/391 [00:06<00:06, 33.01it/s, processed=22400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  45%|████▍     | 175/391 [00:06<00:06, 32.52it/s, processed=22400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  45%|████▍     | 175/391 [00:06<00:06, 32.52it/s, processed=22528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  45%|████▍     | 175/391 [00:06<00:06, 32.52it/s, processed=22656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  45%|████▍     | 175/391 [00:06<00:06, 32.52it/s, processed=22784/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  45%|████▍     | 175/391 [00:06<00:06, 32.52it/s, processed=22912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  46%|████▌     | 179/391 [00:06<00:06, 31.29it/s, processed=22912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  46%|████▌     | 179/391 [00:07<00:06, 31.29it/s, processed=23040/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  46%|████▌     | 179/391 [00:07<00:06, 31.29it/s, processed=23168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  46%|████▌     | 179/391 [00:07<00:06, 31.29it/s, processed=23296/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  46%|████▌     | 179/391 [00:07<00:06, 31.29it/s, processed=23424/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  47%|████▋     | 183/391 [00:07<00:07, 28.59it/s, processed=23424/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  47%|████▋     | 183/391 [00:07<00:07, 28.59it/s, processed=23552/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  47%|████▋     | 183/391 [00:07<00:07, 28.59it/s, processed=23680/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  47%|████▋     | 183/391 [00:07<00:07, 28.59it/s, processed=23808/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  48%|████▊     | 186/391 [00:07<00:07, 27.26it/s, processed=23808/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  48%|████▊     | 186/391 [00:07<00:07, 27.26it/s, processed=23936/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  48%|████▊     | 186/391 [00:07<00:07, 27.26it/s, processed=24064/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  48%|████▊     | 186/391 [00:07<00:07, 27.26it/s, processed=24192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  48%|████▊     | 189/391 [00:07<00:07, 27.56it/s, processed=24192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  48%|████▊     | 189/391 [00:07<00:07, 27.56it/s, processed=24320/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  48%|████▊     | 189/391 [00:07<00:07, 27.56it/s, processed=24448/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  48%|████▊     | 189/391 [00:07<00:07, 27.56it/s, processed=24576/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  48%|████▊     | 189/391 [00:07<00:07, 27.56it/s, processed=24704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  49%|████▉     | 193/391 [00:07<00:06, 30.16it/s, processed=24704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  49%|████▉     | 193/391 [00:07<00:06, 30.16it/s, processed=24832/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  49%|████▉     | 193/391 [00:07<00:06, 30.16it/s, processed=24960/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  49%|████▉     | 193/391 [00:07<00:06, 30.16it/s, processed=25088/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  49%|████▉     | 193/391 [00:07<00:06, 30.16it/s, processed=25216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  50%|█████     | 197/391 [00:07<00:06, 27.99it/s, processed=25216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  50%|█████     | 197/391 [00:07<00:06, 27.99it/s, processed=25344/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  50%|█████     | 197/391 [00:07<00:06, 27.99it/s, processed=25472/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  50%|█████     | 197/391 [00:07<00:06, 27.99it/s, processed=25600/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  50%|█████     | 197/391 [00:07<00:06, 27.99it/s, processed=25728/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  50%|█████     | 197/391 [00:07<00:06, 27.99it/s, processed=25856/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  52%|█████▏    | 202/391 [00:07<00:05, 32.82it/s, processed=25856/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  52%|█████▏    | 202/391 [00:07<00:05, 32.82it/s, processed=25984/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  52%|█████▏    | 202/391 [00:07<00:05, 32.82it/s, processed=26112/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  52%|█████▏    | 202/391 [00:07<00:05, 32.82it/s, processed=26240/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  52%|█████▏    | 202/391 [00:07<00:05, 32.82it/s, processed=26368/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  53%|█████▎    | 206/391 [00:07<00:06, 28.89it/s, processed=26368/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  53%|█████▎    | 206/391 [00:07<00:06, 28.89it/s, processed=26496/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  53%|█████▎    | 206/391 [00:07<00:06, 28.89it/s, processed=26624/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  53%|█████▎    | 206/391 [00:08<00:06, 28.89it/s, processed=26752/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  53%|█████▎    | 206/391 [00:08<00:06, 28.89it/s, processed=26880/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  54%|█████▎    | 210/391 [00:08<00:06, 29.52it/s, processed=26880/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  54%|█████▎    | 210/391 [00:08<00:06, 29.52it/s, processed=27008/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  54%|█████▎    | 210/391 [00:08<00:06, 29.52it/s, processed=27136/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  54%|█████▎    | 210/391 [00:08<00:06, 29.52it/s, processed=27264/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  54%|█████▎    | 210/391 [00:08<00:06, 29.52it/s, processed=27392/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  55%|█████▍    | 214/391 [00:08<00:06, 29.03it/s, processed=27392/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  55%|█████▍    | 214/391 [00:08<00:06, 29.03it/s, processed=27520/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  55%|█████▍    | 214/391 [00:08<00:06, 29.03it/s, processed=27648/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  55%|█████▍    | 214/391 [00:08<00:06, 29.03it/s, processed=27776/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  55%|█████▌    | 217/391 [00:08<00:06, 27.00it/s, processed=27776/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  55%|█████▌    | 217/391 [00:08<00:06, 27.00it/s, processed=27904/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  55%|█████▌    | 217/391 [00:08<00:06, 27.00it/s, processed=28032/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  55%|█████▌    | 217/391 [00:08<00:06, 27.00it/s, processed=28160/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  56%|█████▋    | 220/391 [00:08<00:06, 26.69it/s, processed=28160/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  56%|█████▋    | 220/391 [00:08<00:06, 26.69it/s, processed=28288/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  56%|█████▋    | 220/391 [00:08<00:06, 26.69it/s, processed=28416/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  56%|█████▋    | 220/391 [00:08<00:06, 26.69it/s, processed=28544/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  56%|█████▋    | 220/391 [00:08<00:06, 26.69it/s, processed=28672/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  56%|█████▋    | 220/391 [00:08<00:06, 26.69it/s, processed=28800/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  58%|█████▊    | 225/391 [00:08<00:05, 29.14it/s, processed=28800/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  58%|█████▊    | 225/391 [00:08<00:05, 29.14it/s, processed=28928/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  58%|█████▊    | 225/391 [00:08<00:05, 29.14it/s, processed=29056/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  58%|█████▊    | 225/391 [00:08<00:05, 29.14it/s, processed=29184/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  58%|█████▊    | 228/391 [00:08<00:05, 29.13it/s, processed=29184/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  58%|█████▊    | 228/391 [00:08<00:05, 29.13it/s, processed=29312/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  58%|█████▊    | 228/391 [00:08<00:05, 29.13it/s, processed=29440/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  58%|█████▊    | 228/391 [00:08<00:05, 29.13it/s, processed=29568/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  58%|█████▊    | 228/391 [00:08<00:05, 29.13it/s, processed=29696/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  59%|█████▉    | 232/391 [00:08<00:05, 31.06it/s, processed=29696/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  59%|█████▉    | 232/391 [00:08<00:05, 31.06it/s, processed=29824/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  59%|█████▉    | 232/391 [00:08<00:05, 31.06it/s, processed=29952/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  59%|█████▉    | 232/391 [00:08<00:05, 31.06it/s, processed=30080/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  59%|█████▉    | 232/391 [00:08<00:05, 31.06it/s, processed=30208/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  60%|██████    | 236/391 [00:08<00:05, 28.84it/s, processed=30208/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  60%|██████    | 236/391 [00:08<00:05, 28.84it/s, processed=30336/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  60%|██████    | 236/391 [00:09<00:05, 28.84it/s, processed=30464/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  60%|██████    | 236/391 [00:09<00:05, 28.84it/s, processed=30592/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  60%|██████    | 236/391 [00:09<00:05, 28.84it/s, processed=30720/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  61%|██████▏   | 240/391 [00:09<00:06, 24.79it/s, processed=30720/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  61%|██████▏   | 240/391 [00:09<00:06, 24.79it/s, processed=30848/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  61%|██████▏   | 240/391 [00:09<00:06, 24.79it/s, processed=30976/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  61%|██████▏   | 240/391 [00:09<00:06, 24.79it/s, processed=31104/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  62%|██████▏   | 243/391 [00:09<00:05, 25.47it/s, processed=31104/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  62%|██████▏   | 243/391 [00:09<00:05, 25.47it/s, processed=31232/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  62%|██████▏   | 243/391 [00:09<00:05, 25.47it/s, processed=31360/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  62%|██████▏   | 243/391 [00:09<00:05, 25.47it/s, processed=31488/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  62%|██████▏   | 243/391 [00:09<00:05, 25.47it/s, processed=31616/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  63%|██████▎   | 247/391 [00:09<00:05, 27.29it/s, processed=31616/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  63%|██████▎   | 247/391 [00:09<00:05, 27.29it/s, processed=31744/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  63%|██████▎   | 247/391 [00:09<00:05, 27.29it/s, processed=31872/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  63%|██████▎   | 247/391 [00:09<00:05, 27.29it/s, processed=32000/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  63%|██████▎   | 247/391 [00:09<00:05, 27.29it/s, processed=32128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  64%|██████▍   | 251/391 [00:09<00:05, 27.75it/s, processed=32128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  64%|██████▍   | 251/391 [00:09<00:05, 27.75it/s, processed=32256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  64%|██████▍   | 251/391 [00:09<00:05, 27.75it/s, processed=32384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  64%|██████▍   | 251/391 [00:09<00:05, 27.75it/s, processed=32512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  64%|██████▍   | 251/391 [00:09<00:05, 27.75it/s, processed=32640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  65%|██████▌   | 255/391 [00:09<00:05, 27.16it/s, processed=32640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  65%|██████▌   | 255/391 [00:09<00:05, 27.16it/s, processed=32768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  65%|██████▌   | 255/391 [00:09<00:05, 27.16it/s, processed=32896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  65%|██████▌   | 255/391 [00:09<00:05, 27.16it/s, processed=33024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  65%|██████▌   | 255/391 [00:09<00:05, 27.16it/s, processed=33152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  66%|██████▌   | 259/391 [00:09<00:04, 26.59it/s, processed=33152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  66%|██████▌   | 259/391 [00:09<00:04, 26.59it/s, processed=33280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  66%|██████▌   | 259/391 [00:09<00:04, 26.59it/s, processed=33408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  66%|██████▌   | 259/391 [00:09<00:04, 26.59it/s, processed=33536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  66%|██████▌   | 259/391 [00:09<00:04, 26.59it/s, processed=33664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  67%|██████▋   | 263/391 [00:09<00:04, 27.80it/s, processed=33664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  67%|██████▋   | 263/391 [00:10<00:04, 27.80it/s, processed=33792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  67%|██████▋   | 263/391 [00:10<00:04, 27.80it/s, processed=33920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  67%|██████▋   | 263/391 [00:10<00:04, 27.80it/s, processed=34048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  67%|██████▋   | 263/391 [00:10<00:04, 27.80it/s, processed=34176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  68%|██████▊   | 267/391 [00:10<00:04, 29.37it/s, processed=34176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  68%|██████▊   | 267/391 [00:10<00:04, 29.37it/s, processed=34304/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  68%|██████▊   | 267/391 [00:10<00:04, 29.37it/s, processed=34432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  68%|██████▊   | 267/391 [00:10<00:04, 29.37it/s, processed=34560/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  68%|██████▊   | 267/391 [00:10<00:04, 29.37it/s, processed=34688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  69%|██████▉   | 271/391 [00:10<00:04, 28.21it/s, processed=34688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  69%|██████▉   | 271/391 [00:10<00:04, 28.21it/s, processed=34816/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  69%|██████▉   | 271/391 [00:10<00:04, 28.21it/s, processed=34944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  69%|██████▉   | 271/391 [00:10<00:04, 28.21it/s, processed=35072/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  69%|██████▉   | 271/391 [00:10<00:04, 28.21it/s, processed=35200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  70%|███████   | 275/391 [00:10<00:04, 27.80it/s, processed=35200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  70%|███████   | 275/391 [00:10<00:04, 27.80it/s, processed=35328/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  70%|███████   | 275/391 [00:10<00:04, 27.80it/s, processed=35456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  70%|███████   | 275/391 [00:10<00:04, 27.80it/s, processed=35584/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  70%|███████   | 275/391 [00:10<00:04, 27.80it/s, processed=35712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  71%|███████▏  | 279/391 [00:10<00:03, 29.89it/s, processed=35712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  71%|███████▏  | 279/391 [00:10<00:03, 29.89it/s, processed=35840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  71%|███████▏  | 279/391 [00:10<00:03, 29.89it/s, processed=35968/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  71%|███████▏  | 279/391 [00:10<00:03, 29.89it/s, processed=36096/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  71%|███████▏  | 279/391 [00:10<00:03, 29.89it/s, processed=36224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  71%|███████▏  | 279/391 [00:10<00:03, 29.89it/s, processed=36352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  73%|███████▎  | 284/391 [00:10<00:03, 33.81it/s, processed=36352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  73%|███████▎  | 284/391 [00:10<00:03, 33.81it/s, processed=36480/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  73%|███████▎  | 284/391 [00:10<00:03, 33.81it/s, processed=36608/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  73%|███████▎  | 284/391 [00:10<00:03, 33.81it/s, processed=36736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  73%|███████▎  | 284/391 [00:10<00:03, 33.81it/s, processed=36864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  73%|███████▎  | 284/391 [00:10<00:03, 33.81it/s, processed=36992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  74%|███████▍  | 289/391 [00:10<00:03, 29.90it/s, processed=36992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  74%|███████▍  | 289/391 [00:10<00:03, 29.90it/s, processed=37120/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  74%|███████▍  | 289/391 [00:10<00:03, 29.90it/s, processed=37248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  74%|███████▍  | 289/391 [00:10<00:03, 29.90it/s, processed=37376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  74%|███████▍  | 289/391 [00:10<00:03, 29.90it/s, processed=37504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  75%|███████▍  | 293/391 [00:10<00:03, 29.69it/s, processed=37504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  75%|███████▍  | 293/391 [00:10<00:03, 29.69it/s, processed=37632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  75%|███████▍  | 293/391 [00:11<00:03, 29.69it/s, processed=37760/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  75%|███████▍  | 293/391 [00:11<00:03, 29.69it/s, processed=37888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  75%|███████▍  | 293/391 [00:11<00:03, 29.69it/s, processed=38016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  76%|███████▌  | 297/391 [00:11<00:03, 29.10it/s, processed=38016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  76%|███████▌  | 297/391 [00:11<00:03, 29.10it/s, processed=38144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  76%|███████▌  | 297/391 [00:11<00:03, 29.10it/s, processed=38272/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  76%|███████▌  | 297/391 [00:11<00:03, 29.10it/s, processed=38400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  76%|███████▌  | 297/391 [00:11<00:03, 29.10it/s, processed=38528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  77%|███████▋  | 301/391 [00:11<00:03, 28.59it/s, processed=38528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  77%|███████▋  | 301/391 [00:11<00:03, 28.59it/s, processed=38656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  77%|███████▋  | 301/391 [00:11<00:03, 28.59it/s, processed=38784/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  77%|███████▋  | 301/391 [00:11<00:03, 28.59it/s, processed=38912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  77%|███████▋  | 301/391 [00:11<00:03, 28.59it/s, processed=39040/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  77%|███████▋  | 301/391 [00:11<00:03, 28.59it/s, processed=39168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  78%|███████▊  | 306/391 [00:11<00:02, 33.38it/s, processed=39168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  78%|███████▊  | 306/391 [00:11<00:02, 33.38it/s, processed=39296/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  78%|███████▊  | 306/391 [00:11<00:02, 33.38it/s, processed=39424/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  78%|███████▊  | 306/391 [00:11<00:02, 33.38it/s, processed=39552/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  78%|███████▊  | 306/391 [00:11<00:02, 33.38it/s, processed=39680/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  79%|███████▉  | 310/391 [00:11<00:02, 31.70it/s, processed=39680/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  79%|███████▉  | 310/391 [00:11<00:02, 31.70it/s, processed=39808/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  79%|███████▉  | 310/391 [00:11<00:02, 31.70it/s, processed=39936/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  79%|███████▉  | 310/391 [00:11<00:02, 31.70it/s, processed=40064/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  79%|███████▉  | 310/391 [00:11<00:02, 31.70it/s, processed=40192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  80%|████████  | 314/391 [00:11<00:02, 30.81it/s, processed=40192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  80%|████████  | 314/391 [00:11<00:02, 30.81it/s, processed=40320/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  80%|████████  | 314/391 [00:11<00:02, 30.81it/s, processed=40448/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  80%|████████  | 314/391 [00:11<00:02, 30.81it/s, processed=40576/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  80%|████████  | 314/391 [00:11<00:02, 30.81it/s, processed=40704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  81%|████████▏ | 318/391 [00:11<00:02, 31.00it/s, processed=40704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  81%|████████▏ | 318/391 [00:11<00:02, 31.00it/s, processed=40832/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  81%|████████▏ | 318/391 [00:11<00:02, 31.00it/s, processed=40960/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  81%|████████▏ | 318/391 [00:11<00:02, 31.00it/s, processed=41088/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  81%|████████▏ | 318/391 [00:11<00:02, 31.00it/s, processed=41216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  82%|████████▏ | 322/391 [00:11<00:02, 31.50it/s, processed=41216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  82%|████████▏ | 322/391 [00:11<00:02, 31.50it/s, processed=41344/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  82%|████████▏ | 322/391 [00:11<00:02, 31.50it/s, processed=41472/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  82%|████████▏ | 322/391 [00:11<00:02, 31.50it/s, processed=41600/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  82%|████████▏ | 322/391 [00:11<00:02, 31.50it/s, processed=41728/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  83%|████████▎ | 326/391 [00:12<00:01, 32.67it/s, processed=41728/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  83%|████████▎ | 326/391 [00:12<00:01, 32.67it/s, processed=41856/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  83%|████████▎ | 326/391 [00:12<00:01, 32.67it/s, processed=41984/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  83%|████████▎ | 326/391 [00:12<00:01, 32.67it/s, processed=42112/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  83%|████████▎ | 326/391 [00:12<00:01, 32.67it/s, processed=42240/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  83%|████████▎ | 326/391 [00:12<00:01, 32.67it/s, processed=42368/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  85%|████████▍ | 331/391 [00:12<00:01, 36.15it/s, processed=42368/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  85%|████████▍ | 331/391 [00:12<00:01, 36.15it/s, processed=42496/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  85%|████████▍ | 331/391 [00:12<00:01, 36.15it/s, processed=42624/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  85%|████████▍ | 331/391 [00:12<00:01, 36.15it/s, processed=42752/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  85%|████████▍ | 331/391 [00:12<00:01, 36.15it/s, processed=42880/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  86%|████████▌ | 335/391 [00:12<00:01, 32.57it/s, processed=42880/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  86%|████████▌ | 335/391 [00:12<00:01, 32.57it/s, processed=43008/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  86%|████████▌ | 335/391 [00:12<00:01, 32.57it/s, processed=43136/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  86%|████████▌ | 335/391 [00:12<00:01, 32.57it/s, processed=43264/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  86%|████████▌ | 335/391 [00:12<00:01, 32.57it/s, processed=43392/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  87%|████████▋ | 339/391 [00:12<00:01, 31.92it/s, processed=43392/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  87%|████████▋ | 339/391 [00:12<00:01, 31.92it/s, processed=43520/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  87%|████████▋ | 339/391 [00:12<00:01, 31.92it/s, processed=43648/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  87%|████████▋ | 339/391 [00:12<00:01, 31.92it/s, processed=43776/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  87%|████████▋ | 339/391 [00:12<00:01, 31.92it/s, processed=43904/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  88%|████████▊ | 343/391 [00:12<00:01, 27.30it/s, processed=43904/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  88%|████████▊ | 343/391 [00:12<00:01, 27.30it/s, processed=44032/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  88%|████████▊ | 343/391 [00:12<00:01, 27.30it/s, processed=44160/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  88%|████████▊ | 343/391 [00:12<00:01, 27.30it/s, processed=44288/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  88%|████████▊ | 346/391 [00:12<00:01, 26.94it/s, processed=44288/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  88%|████████▊ | 346/391 [00:12<00:01, 26.94it/s, processed=44416/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  88%|████████▊ | 346/391 [00:12<00:01, 26.94it/s, processed=44544/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  88%|████████▊ | 346/391 [00:12<00:01, 26.94it/s, processed=44672/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  89%|████████▉ | 349/391 [00:12<00:01, 25.30it/s, processed=44672/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  89%|████████▉ | 349/391 [00:12<00:01, 25.30it/s, processed=44800/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  89%|████████▉ | 349/391 [00:13<00:01, 25.30it/s, processed=44928/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  89%|████████▉ | 349/391 [00:13<00:01, 25.30it/s, processed=45056/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  90%|█████████ | 352/391 [00:13<00:01, 21.98it/s, processed=45056/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  90%|█████████ | 352/391 [00:13<00:01, 21.98it/s, processed=45184/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  90%|█████████ | 352/391 [00:13<00:01, 21.98it/s, processed=45312/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  90%|█████████ | 352/391 [00:13<00:01, 21.98it/s, processed=45440/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  91%|█████████ | 355/391 [00:13<00:01, 20.09it/s, processed=45440/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  91%|█████████ | 355/391 [00:13<00:01, 20.09it/s, processed=45568/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  91%|█████████ | 355/391 [00:13<00:01, 20.09it/s, processed=45696/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  91%|█████████ | 355/391 [00:13<00:01, 20.09it/s, processed=45824/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  91%|█████████ | 355/391 [00:13<00:01, 20.09it/s, processed=45952/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  92%|█████████▏| 359/391 [00:13<00:01, 24.01it/s, processed=45952/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  92%|█████████▏| 359/391 [00:13<00:01, 24.01it/s, processed=46080/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  92%|█████████▏| 359/391 [00:13<00:01, 24.01it/s, processed=46208/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  92%|█████████▏| 359/391 [00:13<00:01, 24.01it/s, processed=46336/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  92%|█████████▏| 359/391 [00:13<00:01, 24.01it/s, processed=46464/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  93%|█████████▎| 363/391 [00:13<00:01, 25.49it/s, processed=46464/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  93%|█████████▎| 363/391 [00:13<00:01, 25.49it/s, processed=46592/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  93%|█████████▎| 363/391 [00:13<00:01, 25.49it/s, processed=46720/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  93%|█████████▎| 363/391 [00:13<00:01, 25.49it/s, processed=46848/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  93%|█████████▎| 363/391 [00:13<00:01, 25.49it/s, processed=46976/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  94%|█████████▍| 367/391 [00:13<00:00, 27.74it/s, processed=46976/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  94%|█████████▍| 367/391 [00:13<00:00, 27.74it/s, processed=47104/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  94%|█████████▍| 367/391 [00:13<00:00, 27.74it/s, processed=47232/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  94%|█████████▍| 367/391 [00:13<00:00, 27.74it/s, processed=47360/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  94%|█████████▍| 367/391 [00:13<00:00, 27.74it/s, processed=47488/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  95%|█████████▍| 371/391 [00:13<00:00, 28.68it/s, processed=47488/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  95%|█████████▍| 371/391 [00:13<00:00, 28.68it/s, processed=47616/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  95%|█████████▍| 371/391 [00:13<00:00, 28.68it/s, processed=47744/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  95%|█████████▍| 371/391 [00:13<00:00, 28.68it/s, processed=47872/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  96%|█████████▌| 374/391 [00:13<00:00, 26.74it/s, processed=47872/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  96%|█████████▌| 374/391 [00:13<00:00, 26.74it/s, processed=48000/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  96%|█████████▌| 374/391 [00:13<00:00, 26.74it/s, processed=48128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  96%|█████████▌| 374/391 [00:13<00:00, 26.74it/s, processed=48256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  96%|█████████▋| 377/391 [00:13<00:00, 25.94it/s, processed=48256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  96%|█████████▋| 377/391 [00:14<00:00, 25.94it/s, processed=48384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  96%|█████████▋| 377/391 [00:14<00:00, 25.94it/s, processed=48512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  96%|█████████▋| 377/391 [00:14<00:00, 25.94it/s, processed=48640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  97%|█████████▋| 380/391 [00:14<00:00, 26.68it/s, processed=48640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  97%|█████████▋| 380/391 [00:14<00:00, 26.68it/s, processed=48768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  97%|█████████▋| 380/391 [00:14<00:00, 26.68it/s, processed=48896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  97%|█████████▋| 380/391 [00:14<00:00, 26.68it/s, processed=49024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  98%|█████████▊| 383/391 [00:14<00:00, 25.84it/s, processed=49024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  98%|█████████▊| 383/391 [00:14<00:00, 25.84it/s, processed=49152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  98%|█████████▊| 383/391 [00:14<00:00, 25.84it/s, processed=49280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  98%|█████████▊| 383/391 [00:14<00:00, 25.84it/s, processed=49408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  98%|█████████▊| 383/391 [00:14<00:00, 25.84it/s, processed=49536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  98%|█████████▊| 383/391 [00:14<00:00, 25.84it/s, processed=49664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  98%|█████████▊| 383/391 [00:14<00:00, 25.84it/s, processed=49792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  99%|█████████▉| 389/391 [00:14<00:00, 32.22it/s, processed=49792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  99%|█████████▉| 389/391 [00:14<00:00, 32.22it/s, processed=49920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing uncertainty scores:  99%|█████████▉| 389/391 [00:14<00:00, 32.22it/s, processed=50000/50000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                      \u001b[A\u001b[A\n",
      "Computing strategy scores:  25%|██▌       | 1/4 [00:14<00:43, 14.44s/it, stage=uncertainty]\u001b[A\n",
      "Computing strategy scores:  25%|██▌       | 1/4 [00:14<00:43, 14.44s/it, stage=diversity]  \u001b[A\n",
      "\n",
      "Extracting features for selected samples:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Extracting features for selected samples:  12%|█▎        | 1/8 [00:00<00:06,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Extracting features for selected samples:  88%|████████▊ | 7/8 [00:01<00:00,  8.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                       \u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   0%|          | 0/391 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   0%|          | 0/391 [00:00<?, ?it/s, processed=128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   0%|          | 1/391 [00:00<06:27,  1.01it/s, processed=128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   0%|          | 1/391 [00:01<06:27,  1.01it/s, processed=256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   1%|          | 2/391 [00:01<03:20,  1.94it/s, processed=256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   1%|          | 2/391 [00:01<03:20,  1.94it/s, processed=384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   1%|          | 3/391 [00:01<02:13,  2.91it/s, processed=384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   1%|          | 3/391 [00:01<02:13,  2.91it/s, processed=512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   1%|          | 4/391 [00:01<01:45,  3.67it/s, processed=512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   1%|          | 4/391 [00:01<01:45,  3.67it/s, processed=640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   1%|▏         | 5/391 [00:01<01:26,  4.47it/s, processed=640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   1%|▏         | 5/391 [00:01<01:26,  4.47it/s, processed=768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   2%|▏         | 6/391 [00:01<01:14,  5.17it/s, processed=768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   2%|▏         | 6/391 [00:01<01:14,  5.17it/s, processed=896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   2%|▏         | 7/391 [00:01<01:07,  5.72it/s, processed=896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   2%|▏         | 7/391 [00:02<01:07,  5.72it/s, processed=1024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   2%|▏         | 8/391 [00:02<01:01,  6.21it/s, processed=1024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   2%|▏         | 8/391 [00:02<01:01,  6.21it/s, processed=1152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   2%|▏         | 9/391 [00:02<00:58,  6.57it/s, processed=1152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   2%|▏         | 9/391 [00:02<00:58,  6.57it/s, processed=1280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   3%|▎         | 10/391 [00:02<01:00,  6.35it/s, processed=1280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   3%|▎         | 10/391 [00:02<01:00,  6.35it/s, processed=1408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   3%|▎         | 11/391 [00:02<00:58,  6.49it/s, processed=1408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   3%|▎         | 11/391 [00:02<00:58,  6.49it/s, processed=1536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   3%|▎         | 12/391 [00:02<00:57,  6.63it/s, processed=1536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   3%|▎         | 12/391 [00:02<00:57,  6.63it/s, processed=1664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   3%|▎         | 13/391 [00:02<00:55,  6.78it/s, processed=1664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   3%|▎         | 13/391 [00:02<00:55,  6.78it/s, processed=1792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   4%|▎         | 14/391 [00:02<00:54,  6.96it/s, processed=1792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   4%|▎         | 14/391 [00:03<00:54,  6.96it/s, processed=1920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   4%|▍         | 15/391 [00:03<00:52,  7.13it/s, processed=1920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   4%|▍         | 15/391 [00:03<00:52,  7.13it/s, processed=2048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   4%|▍         | 16/391 [00:03<00:52,  7.20it/s, processed=2048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   4%|▍         | 16/391 [00:03<00:52,  7.20it/s, processed=2176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   4%|▍         | 17/391 [00:03<00:52,  7.17it/s, processed=2176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   4%|▍         | 17/391 [00:03<00:52,  7.17it/s, processed=2304/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   5%|▍         | 18/391 [00:03<00:54,  6.81it/s, processed=2304/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   5%|▍         | 18/391 [00:03<00:54,  6.81it/s, processed=2432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   5%|▍         | 19/391 [00:03<00:57,  6.50it/s, processed=2432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   5%|▍         | 19/391 [00:03<00:57,  6.50it/s, processed=2560/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   5%|▌         | 20/391 [00:03<00:59,  6.20it/s, processed=2560/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   5%|▌         | 20/391 [00:04<00:59,  6.20it/s, processed=2688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   5%|▌         | 21/391 [00:04<01:03,  5.81it/s, processed=2688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   5%|▌         | 21/391 [00:04<01:03,  5.81it/s, processed=2816/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   6%|▌         | 22/391 [00:04<01:02,  5.86it/s, processed=2816/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   6%|▌         | 22/391 [00:04<01:02,  5.86it/s, processed=2944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   6%|▌         | 23/391 [00:04<00:58,  6.24it/s, processed=2944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   6%|▌         | 23/391 [00:04<00:58,  6.24it/s, processed=3072/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   6%|▌         | 24/391 [00:04<00:58,  6.32it/s, processed=3072/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   6%|▌         | 24/391 [00:04<00:58,  6.32it/s, processed=3200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   6%|▋         | 25/391 [00:04<00:56,  6.47it/s, processed=3200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   6%|▋         | 25/391 [00:04<00:56,  6.47it/s, processed=3328/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   7%|▋         | 26/391 [00:04<00:54,  6.65it/s, processed=3328/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   7%|▋         | 26/391 [00:04<00:54,  6.65it/s, processed=3456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   7%|▋         | 27/391 [00:04<00:53,  6.75it/s, processed=3456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   7%|▋         | 27/391 [00:05<00:53,  6.75it/s, processed=3584/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   7%|▋         | 28/391 [00:05<00:53,  6.83it/s, processed=3584/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   7%|▋         | 28/391 [00:05<00:53,  6.83it/s, processed=3712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   7%|▋         | 29/391 [00:05<00:52,  6.88it/s, processed=3712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   7%|▋         | 29/391 [00:05<00:52,  6.88it/s, processed=3840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   8%|▊         | 30/391 [00:05<00:51,  7.02it/s, processed=3840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   8%|▊         | 30/391 [00:05<00:51,  7.02it/s, processed=3968/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   8%|▊         | 31/391 [00:05<00:51,  7.00it/s, processed=3968/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   8%|▊         | 31/391 [00:05<00:51,  7.00it/s, processed=4096/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   8%|▊         | 32/391 [00:05<00:51,  7.01it/s, processed=4096/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   8%|▊         | 32/391 [00:05<00:51,  7.01it/s, processed=4224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   8%|▊         | 33/391 [00:05<00:51,  6.99it/s, processed=4224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   8%|▊         | 33/391 [00:05<00:51,  6.99it/s, processed=4352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   9%|▊         | 34/391 [00:05<00:51,  6.90it/s, processed=4352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   9%|▊         | 34/391 [00:06<00:51,  6.90it/s, processed=4480/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   9%|▉         | 35/391 [00:06<00:51,  6.97it/s, processed=4480/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   9%|▉         | 35/391 [00:06<00:51,  6.97it/s, processed=4608/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   9%|▉         | 36/391 [00:06<00:53,  6.60it/s, processed=4608/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   9%|▉         | 36/391 [00:06<00:53,  6.60it/s, processed=4736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   9%|▉         | 37/391 [00:06<00:51,  6.92it/s, processed=4736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:   9%|▉         | 37/391 [00:06<00:51,  6.92it/s, processed=4864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  10%|▉         | 38/391 [00:06<00:53,  6.63it/s, processed=4864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  10%|▉         | 38/391 [00:06<00:53,  6.63it/s, processed=4992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  10%|▉         | 39/391 [00:06<00:52,  6.72it/s, processed=4992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  10%|▉         | 39/391 [00:06<00:52,  6.72it/s, processed=5120/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  10%|█         | 40/391 [00:06<00:51,  6.81it/s, processed=5120/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  10%|█         | 40/391 [00:06<00:51,  6.81it/s, processed=5248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  10%|█         | 41/391 [00:06<00:50,  6.89it/s, processed=5248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  10%|█         | 41/391 [00:07<00:50,  6.89it/s, processed=5376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  11%|█         | 42/391 [00:07<00:49,  6.99it/s, processed=5376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  11%|█         | 42/391 [00:07<00:49,  6.99it/s, processed=5504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  11%|█         | 43/391 [00:07<00:50,  6.92it/s, processed=5504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  11%|█         | 43/391 [00:07<00:50,  6.92it/s, processed=5632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  11%|█▏        | 44/391 [00:07<00:55,  6.22it/s, processed=5632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  11%|█▏        | 44/391 [00:07<00:55,  6.22it/s, processed=5760/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  12%|█▏        | 45/391 [00:07<00:59,  5.84it/s, processed=5760/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  12%|█▏        | 45/391 [00:07<00:59,  5.84it/s, processed=5888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  12%|█▏        | 46/391 [00:07<01:01,  5.59it/s, processed=5888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  12%|█▏        | 46/391 [00:07<01:01,  5.59it/s, processed=6016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  12%|█▏        | 47/391 [00:07<00:59,  5.74it/s, processed=6016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  12%|█▏        | 47/391 [00:08<00:59,  5.74it/s, processed=6144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  12%|█▏        | 48/391 [00:08<00:56,  6.10it/s, processed=6144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  12%|█▏        | 48/391 [00:08<00:56,  6.10it/s, processed=6272/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  13%|█▎        | 49/391 [00:08<00:56,  6.00it/s, processed=6272/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  13%|█▎        | 49/391 [00:08<00:56,  6.00it/s, processed=6400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  13%|█▎        | 50/391 [00:08<00:54,  6.23it/s, processed=6400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  13%|█▎        | 50/391 [00:08<00:54,  6.23it/s, processed=6528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  13%|█▎        | 51/391 [00:08<00:54,  6.19it/s, processed=6528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  13%|█▎        | 51/391 [00:08<00:54,  6.19it/s, processed=6656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  13%|█▎        | 52/391 [00:08<00:54,  6.25it/s, processed=6656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  13%|█▎        | 52/391 [00:08<00:54,  6.25it/s, processed=6784/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  14%|█▎        | 53/391 [00:08<00:52,  6.43it/s, processed=6784/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  14%|█▎        | 53/391 [00:09<00:52,  6.43it/s, processed=6912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  14%|█▍        | 54/391 [00:09<00:52,  6.42it/s, processed=6912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  14%|█▍        | 54/391 [00:09<00:52,  6.42it/s, processed=7040/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  14%|█▍        | 55/391 [00:09<00:51,  6.50it/s, processed=7040/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  14%|█▍        | 55/391 [00:09<00:51,  6.50it/s, processed=7168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  14%|█▍        | 56/391 [00:09<00:51,  6.50it/s, processed=7168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  14%|█▍        | 56/391 [00:09<00:51,  6.50it/s, processed=7296/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  15%|█▍        | 57/391 [00:09<00:52,  6.36it/s, processed=7296/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  15%|█▍        | 57/391 [00:09<00:52,  6.36it/s, processed=7424/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  15%|█▍        | 58/391 [00:09<00:50,  6.61it/s, processed=7424/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  15%|█▍        | 58/391 [00:09<00:50,  6.61it/s, processed=7552/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  15%|█▌        | 59/391 [00:09<00:49,  6.70it/s, processed=7552/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  15%|█▌        | 59/391 [00:09<00:49,  6.70it/s, processed=7680/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  15%|█▌        | 60/391 [00:09<00:49,  6.70it/s, processed=7680/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  15%|█▌        | 60/391 [00:10<00:49,  6.70it/s, processed=7808/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  16%|█▌        | 61/391 [00:10<00:48,  6.77it/s, processed=7808/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  16%|█▌        | 61/391 [00:10<00:48,  6.77it/s, processed=7936/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  16%|█▌        | 62/391 [00:10<00:48,  6.83it/s, processed=7936/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  16%|█▌        | 62/391 [00:10<00:48,  6.83it/s, processed=8064/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  16%|█▌        | 63/391 [00:10<00:47,  6.90it/s, processed=8064/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  16%|█▌        | 63/391 [00:10<00:47,  6.90it/s, processed=8192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  16%|█▋        | 64/391 [00:10<00:46,  7.04it/s, processed=8192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  16%|█▋        | 64/391 [00:10<00:46,  7.04it/s, processed=8320/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  17%|█▋        | 65/391 [00:10<00:46,  6.95it/s, processed=8320/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  17%|█▋        | 65/391 [00:10<00:46,  6.95it/s, processed=8448/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  17%|█▋        | 66/391 [00:10<00:47,  6.83it/s, processed=8448/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  17%|█▋        | 66/391 [00:10<00:47,  6.83it/s, processed=8576/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  17%|█▋        | 67/391 [00:10<00:48,  6.67it/s, processed=8576/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  17%|█▋        | 67/391 [00:11<00:48,  6.67it/s, processed=8704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  17%|█▋        | 68/391 [00:11<00:53,  6.07it/s, processed=8704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  17%|█▋        | 68/391 [00:11<00:53,  6.07it/s, processed=8832/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  18%|█▊        | 69/391 [00:11<00:56,  5.72it/s, processed=8832/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  18%|█▊        | 69/391 [00:11<00:56,  5.72it/s, processed=8960/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  18%|█▊        | 70/391 [00:11<00:58,  5.48it/s, processed=8960/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  18%|█▊        | 70/391 [00:11<00:58,  5.48it/s, processed=9088/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  18%|█▊        | 71/391 [00:11<00:55,  5.78it/s, processed=9088/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  18%|█▊        | 71/391 [00:11<00:55,  5.78it/s, processed=9216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  18%|█▊        | 72/391 [00:11<00:51,  6.14it/s, processed=9216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  18%|█▊        | 72/391 [00:11<00:51,  6.14it/s, processed=9344/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  19%|█▊        | 73/391 [00:12<00:50,  6.31it/s, processed=9344/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  19%|█▊        | 73/391 [00:12<00:50,  6.31it/s, processed=9472/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  19%|█▉        | 74/391 [00:12<00:48,  6.59it/s, processed=9472/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  19%|█▉        | 74/391 [00:12<00:48,  6.59it/s, processed=9600/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  19%|█▉        | 75/391 [00:12<00:45,  6.87it/s, processed=9600/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  19%|█▉        | 75/391 [00:12<00:45,  6.87it/s, processed=9728/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  19%|█▉        | 76/391 [00:12<00:45,  6.97it/s, processed=9728/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  19%|█▉        | 76/391 [00:12<00:45,  6.97it/s, processed=9856/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  20%|█▉        | 77/391 [00:12<00:44,  7.03it/s, processed=9856/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  20%|█▉        | 77/391 [00:12<00:44,  7.03it/s, processed=9984/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  20%|█▉        | 78/391 [00:12<00:44,  6.98it/s, processed=9984/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  20%|█▉        | 78/391 [00:12<00:44,  6.98it/s, processed=10112/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  20%|██        | 79/391 [00:12<00:44,  7.04it/s, processed=10112/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  20%|██        | 79/391 [00:12<00:44,  7.04it/s, processed=10240/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  20%|██        | 80/391 [00:12<00:43,  7.17it/s, processed=10240/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  20%|██        | 80/391 [00:13<00:43,  7.17it/s, processed=10368/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  21%|██        | 81/391 [00:13<00:42,  7.21it/s, processed=10368/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  21%|██        | 81/391 [00:13<00:42,  7.21it/s, processed=10496/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  21%|██        | 82/391 [00:13<00:42,  7.24it/s, processed=10496/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  21%|██        | 82/391 [00:13<00:42,  7.24it/s, processed=10624/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  21%|██        | 83/391 [00:13<00:42,  7.25it/s, processed=10624/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  21%|██        | 83/391 [00:13<00:42,  7.25it/s, processed=10752/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  21%|██▏       | 84/391 [00:13<00:42,  7.18it/s, processed=10752/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  21%|██▏       | 84/391 [00:13<00:42,  7.18it/s, processed=10880/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  22%|██▏       | 85/391 [00:13<00:43,  7.07it/s, processed=10880/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  22%|██▏       | 85/391 [00:13<00:43,  7.07it/s, processed=11008/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  22%|██▏       | 86/391 [00:13<00:45,  6.67it/s, processed=11008/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  22%|██▏       | 86/391 [00:13<00:45,  6.67it/s, processed=11136/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  22%|██▏       | 87/391 [00:13<00:46,  6.57it/s, processed=11136/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  22%|██▏       | 87/391 [00:14<00:46,  6.57it/s, processed=11264/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  23%|██▎       | 88/391 [00:14<00:46,  6.56it/s, processed=11264/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  23%|██▎       | 88/391 [00:14<00:46,  6.56it/s, processed=11392/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  23%|██▎       | 89/391 [00:14<00:48,  6.25it/s, processed=11392/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  23%|██▎       | 89/391 [00:14<00:48,  6.25it/s, processed=11520/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  23%|██▎       | 90/391 [00:14<00:46,  6.45it/s, processed=11520/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  23%|██▎       | 90/391 [00:14<00:46,  6.45it/s, processed=11648/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  23%|██▎       | 91/391 [00:14<00:48,  6.13it/s, processed=11648/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  23%|██▎       | 91/391 [00:14<00:48,  6.13it/s, processed=11776/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  24%|██▎       | 92/391 [00:14<00:51,  5.76it/s, processed=11776/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  24%|██▎       | 92/391 [00:15<00:51,  5.76it/s, processed=11904/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  24%|██▍       | 93/391 [00:15<00:57,  5.17it/s, processed=11904/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  24%|██▍       | 93/391 [00:15<00:57,  5.17it/s, processed=12032/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  24%|██▍       | 94/391 [00:15<00:57,  5.19it/s, processed=12032/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  24%|██▍       | 94/391 [00:15<00:57,  5.19it/s, processed=12160/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  24%|██▍       | 95/391 [00:15<00:56,  5.28it/s, processed=12160/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  24%|██▍       | 95/391 [00:15<00:56,  5.28it/s, processed=12288/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  25%|██▍       | 96/391 [00:15<00:53,  5.50it/s, processed=12288/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  25%|██▍       | 96/391 [00:15<00:53,  5.50it/s, processed=12416/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  25%|██▍       | 97/391 [00:15<00:52,  5.62it/s, processed=12416/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  25%|██▍       | 97/391 [00:15<00:52,  5.62it/s, processed=12544/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  25%|██▌       | 98/391 [00:15<00:50,  5.86it/s, processed=12544/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  25%|██▌       | 98/391 [00:16<00:50,  5.86it/s, processed=12672/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  25%|██▌       | 99/391 [00:16<00:45,  6.42it/s, processed=12672/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  25%|██▌       | 99/391 [00:16<00:45,  6.42it/s, processed=12800/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  26%|██▌       | 100/391 [00:16<00:44,  6.47it/s, processed=12800/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  26%|██▌       | 100/391 [00:16<00:44,  6.47it/s, processed=12928/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  26%|██▌       | 101/391 [00:16<00:45,  6.36it/s, processed=12928/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  26%|██▌       | 101/391 [00:16<00:45,  6.36it/s, processed=13056/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  26%|██▌       | 102/391 [00:16<00:46,  6.23it/s, processed=13056/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  26%|██▌       | 102/391 [00:16<00:46,  6.23it/s, processed=13184/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  26%|██▋       | 103/391 [00:16<00:48,  5.92it/s, processed=13184/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  26%|██▋       | 103/391 [00:16<00:48,  5.92it/s, processed=13312/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  27%|██▋       | 104/391 [00:16<00:46,  6.13it/s, processed=13312/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  27%|██▋       | 104/391 [00:17<00:46,  6.13it/s, processed=13440/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  27%|██▋       | 105/391 [00:17<00:45,  6.29it/s, processed=13440/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  27%|██▋       | 105/391 [00:17<00:45,  6.29it/s, processed=13568/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  27%|██▋       | 106/391 [00:17<00:43,  6.49it/s, processed=13568/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  27%|██▋       | 106/391 [00:17<00:43,  6.49it/s, processed=13696/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  27%|██▋       | 107/391 [00:17<00:43,  6.46it/s, processed=13696/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  27%|██▋       | 107/391 [00:17<00:43,  6.46it/s, processed=13824/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  28%|██▊       | 108/391 [00:17<00:43,  6.52it/s, processed=13824/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  28%|██▊       | 108/391 [00:17<00:43,  6.52it/s, processed=13952/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  28%|██▊       | 109/391 [00:17<00:43,  6.53it/s, processed=13952/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  28%|██▊       | 109/391 [00:17<00:43,  6.53it/s, processed=14080/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  28%|██▊       | 110/391 [00:17<00:46,  6.08it/s, processed=14080/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  28%|██▊       | 110/391 [00:17<00:46,  6.08it/s, processed=14208/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  28%|██▊       | 111/391 [00:17<00:45,  6.14it/s, processed=14208/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  28%|██▊       | 111/391 [00:18<00:45,  6.14it/s, processed=14336/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  29%|██▊       | 112/391 [00:18<00:44,  6.28it/s, processed=14336/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  29%|██▊       | 112/391 [00:18<00:44,  6.28it/s, processed=14464/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  29%|██▉       | 113/391 [00:18<00:41,  6.62it/s, processed=14464/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  29%|██▉       | 113/391 [00:18<00:41,  6.62it/s, processed=14592/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  29%|██▉       | 114/391 [00:18<00:43,  6.34it/s, processed=14592/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  29%|██▉       | 114/391 [00:18<00:43,  6.34it/s, processed=14720/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  29%|██▉       | 115/391 [00:18<00:45,  6.01it/s, processed=14720/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  29%|██▉       | 115/391 [00:18<00:45,  6.01it/s, processed=14848/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  30%|██▉       | 116/391 [00:18<00:47,  5.74it/s, processed=14848/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  30%|██▉       | 116/391 [00:19<00:47,  5.74it/s, processed=14976/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  30%|██▉       | 117/391 [00:19<00:48,  5.68it/s, processed=14976/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  30%|██▉       | 117/391 [00:19<00:48,  5.68it/s, processed=15104/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  30%|███       | 118/391 [00:19<00:44,  6.13it/s, processed=15104/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  30%|███       | 118/391 [00:19<00:44,  6.13it/s, processed=15232/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  30%|███       | 119/391 [00:19<00:41,  6.52it/s, processed=15232/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  30%|███       | 119/391 [00:19<00:41,  6.52it/s, processed=15360/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  31%|███       | 120/391 [00:19<00:40,  6.72it/s, processed=15360/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  31%|███       | 120/391 [00:19<00:40,  6.72it/s, processed=15488/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  31%|███       | 121/391 [00:19<00:39,  6.80it/s, processed=15488/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  31%|███       | 121/391 [00:19<00:39,  6.80it/s, processed=15616/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  31%|███       | 122/391 [00:19<00:39,  6.88it/s, processed=15616/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  31%|███       | 122/391 [00:19<00:39,  6.88it/s, processed=15744/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  31%|███▏      | 123/391 [00:19<00:39,  6.85it/s, processed=15744/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  31%|███▏      | 123/391 [00:19<00:39,  6.85it/s, processed=15872/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  32%|███▏      | 124/391 [00:19<00:38,  6.87it/s, processed=15872/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  32%|███▏      | 124/391 [00:20<00:38,  6.87it/s, processed=16000/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  32%|███▏      | 125/391 [00:20<00:39,  6.71it/s, processed=16000/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  32%|███▏      | 125/391 [00:20<00:39,  6.71it/s, processed=16128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  32%|███▏      | 126/391 [00:20<00:38,  6.81it/s, processed=16128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  32%|███▏      | 126/391 [00:20<00:38,  6.81it/s, processed=16256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  32%|███▏      | 127/391 [00:20<00:37,  6.97it/s, processed=16256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  32%|███▏      | 127/391 [00:20<00:37,  6.97it/s, processed=16384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  33%|███▎      | 128/391 [00:20<00:37,  6.95it/s, processed=16384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  33%|███▎      | 128/391 [00:20<00:37,  6.95it/s, processed=16512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  33%|███▎      | 129/391 [00:20<00:36,  7.14it/s, processed=16512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  33%|███▎      | 129/391 [00:20<00:36,  7.14it/s, processed=16640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  33%|███▎      | 130/391 [00:20<00:41,  6.25it/s, processed=16640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  33%|███▎      | 130/391 [00:21<00:41,  6.25it/s, processed=16768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  34%|███▎      | 131/391 [00:21<00:39,  6.54it/s, processed=16768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  34%|███▎      | 131/391 [00:21<00:39,  6.54it/s, processed=16896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  34%|███▍      | 132/391 [00:21<00:38,  6.75it/s, processed=16896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  34%|███▍      | 132/391 [00:21<00:38,  6.75it/s, processed=17024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  34%|███▍      | 133/391 [00:21<00:37,  6.95it/s, processed=17024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  34%|███▍      | 133/391 [00:21<00:37,  6.95it/s, processed=17152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  34%|███▍      | 134/391 [00:21<00:36,  7.08it/s, processed=17152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  34%|███▍      | 134/391 [00:21<00:36,  7.08it/s, processed=17280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  35%|███▍      | 135/391 [00:21<00:34,  7.35it/s, processed=17280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  35%|███▍      | 135/391 [00:21<00:34,  7.35it/s, processed=17408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  35%|███▍      | 136/391 [00:21<00:34,  7.35it/s, processed=17408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  35%|███▍      | 136/391 [00:21<00:34,  7.35it/s, processed=17536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  35%|███▌      | 137/391 [00:21<00:34,  7.28it/s, processed=17536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  35%|███▌      | 137/391 [00:22<00:34,  7.28it/s, processed=17664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  35%|███▌      | 138/391 [00:22<00:40,  6.30it/s, processed=17664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  35%|███▌      | 138/391 [00:22<00:40,  6.30it/s, processed=17792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  36%|███▌      | 139/391 [00:22<00:42,  5.95it/s, processed=17792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  36%|███▌      | 139/391 [00:22<00:42,  5.95it/s, processed=17920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  36%|███▌      | 140/391 [00:22<00:45,  5.54it/s, processed=17920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  36%|███▌      | 140/391 [00:22<00:45,  5.54it/s, processed=18048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  36%|███▌      | 141/391 [00:22<00:45,  5.48it/s, processed=18048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  36%|███▌      | 141/391 [00:22<00:45,  5.48it/s, processed=18176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  36%|███▋      | 142/391 [00:22<00:44,  5.64it/s, processed=18176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  36%|███▋      | 142/391 [00:22<00:44,  5.64it/s, processed=18304/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  37%|███▋      | 143/391 [00:22<00:41,  5.92it/s, processed=18304/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  37%|███▋      | 143/391 [00:23<00:41,  5.92it/s, processed=18432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  37%|███▋      | 144/391 [00:23<00:38,  6.42it/s, processed=18432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  37%|███▋      | 144/391 [00:23<00:38,  6.42it/s, processed=18560/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  37%|███▋      | 145/391 [00:23<00:36,  6.74it/s, processed=18560/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  37%|███▋      | 145/391 [00:23<00:36,  6.74it/s, processed=18688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  37%|███▋      | 146/391 [00:23<00:35,  6.95it/s, processed=18688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  37%|███▋      | 146/391 [00:23<00:35,  6.95it/s, processed=18816/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  38%|███▊      | 147/391 [00:23<00:34,  7.10it/s, processed=18816/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  38%|███▊      | 147/391 [00:23<00:34,  7.10it/s, processed=18944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  38%|███▊      | 148/391 [00:23<00:34,  7.14it/s, processed=18944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  38%|███▊      | 148/391 [00:23<00:34,  7.14it/s, processed=19072/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  38%|███▊      | 149/391 [00:23<00:33,  7.15it/s, processed=19072/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  38%|███▊      | 149/391 [00:23<00:33,  7.15it/s, processed=19200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  38%|███▊      | 150/391 [00:23<00:33,  7.12it/s, processed=19200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  38%|███▊      | 150/391 [00:24<00:33,  7.12it/s, processed=19328/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  39%|███▊      | 151/391 [00:24<00:32,  7.28it/s, processed=19328/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  39%|███▊      | 151/391 [00:24<00:32,  7.28it/s, processed=19456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  39%|███▉      | 152/391 [00:24<00:33,  7.09it/s, processed=19456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  39%|███▉      | 152/391 [00:24<00:33,  7.09it/s, processed=19584/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  39%|███▉      | 153/391 [00:24<00:33,  7.19it/s, processed=19584/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  39%|███▉      | 153/391 [00:24<00:33,  7.19it/s, processed=19712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  39%|███▉      | 154/391 [00:24<00:33,  7.02it/s, processed=19712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  39%|███▉      | 154/391 [00:24<00:33,  7.02it/s, processed=19840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  40%|███▉      | 155/391 [00:24<00:33,  7.02it/s, processed=19840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  40%|███▉      | 155/391 [00:24<00:33,  7.02it/s, processed=19968/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  40%|███▉      | 156/391 [00:24<00:32,  7.30it/s, processed=19968/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  40%|███▉      | 156/391 [00:24<00:32,  7.30it/s, processed=20096/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  40%|████      | 157/391 [00:24<00:31,  7.32it/s, processed=20096/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  40%|████      | 157/391 [00:25<00:31,  7.32it/s, processed=20224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  40%|████      | 158/391 [00:25<00:32,  7.23it/s, processed=20224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  40%|████      | 158/391 [00:25<00:32,  7.23it/s, processed=20352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  41%|████      | 159/391 [00:25<00:31,  7.34it/s, processed=20352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  41%|████      | 159/391 [00:25<00:31,  7.34it/s, processed=20480/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  41%|████      | 160/391 [00:25<00:31,  7.42it/s, processed=20480/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  41%|████      | 160/391 [00:25<00:31,  7.42it/s, processed=20608/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  41%|████      | 161/391 [00:25<00:31,  7.23it/s, processed=20608/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  41%|████      | 161/391 [00:25<00:31,  7.23it/s, processed=20736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  41%|████▏     | 162/391 [00:25<00:32,  7.12it/s, processed=20736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  41%|████▏     | 162/391 [00:25<00:32,  7.12it/s, processed=20864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  42%|████▏     | 163/391 [00:25<00:33,  6.74it/s, processed=20864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  42%|████▏     | 163/391 [00:25<00:33,  6.74it/s, processed=20992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  42%|████▏     | 164/391 [00:25<00:37,  6.01it/s, processed=20992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  42%|████▏     | 164/391 [00:26<00:37,  6.01it/s, processed=21120/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  42%|████▏     | 165/391 [00:26<00:39,  5.74it/s, processed=21120/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  42%|████▏     | 165/391 [00:26<00:39,  5.74it/s, processed=21248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  42%|████▏     | 166/391 [00:26<00:39,  5.70it/s, processed=21248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  42%|████▏     | 166/391 [00:26<00:39,  5.70it/s, processed=21376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  43%|████▎     | 167/391 [00:26<00:38,  5.89it/s, processed=21376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  43%|████▎     | 167/391 [00:26<00:38,  5.89it/s, processed=21504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  43%|████▎     | 168/391 [00:26<00:35,  6.35it/s, processed=21504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  43%|████▎     | 168/391 [00:26<00:35,  6.35it/s, processed=21632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  43%|████▎     | 169/391 [00:26<00:35,  6.17it/s, processed=21632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  43%|████▎     | 169/391 [00:26<00:35,  6.17it/s, processed=21760/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  43%|████▎     | 170/391 [00:26<00:34,  6.38it/s, processed=21760/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  43%|████▎     | 170/391 [00:27<00:34,  6.38it/s, processed=21888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  44%|████▎     | 171/391 [00:27<00:33,  6.59it/s, processed=21888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  44%|████▎     | 171/391 [00:27<00:33,  6.59it/s, processed=22016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  44%|████▍     | 172/391 [00:27<00:31,  6.88it/s, processed=22016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  44%|████▍     | 172/391 [00:27<00:31,  6.88it/s, processed=22144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  44%|████▍     | 173/391 [00:27<00:31,  6.96it/s, processed=22144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  44%|████▍     | 173/391 [00:27<00:31,  6.96it/s, processed=22272/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  45%|████▍     | 174/391 [00:27<00:30,  7.08it/s, processed=22272/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  45%|████▍     | 174/391 [00:27<00:30,  7.08it/s, processed=22400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  45%|████▍     | 175/391 [00:27<00:30,  7.18it/s, processed=22400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  45%|████▍     | 175/391 [00:27<00:30,  7.18it/s, processed=22528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  45%|████▌     | 176/391 [00:27<00:29,  7.27it/s, processed=22528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  45%|████▌     | 176/391 [00:27<00:29,  7.27it/s, processed=22656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  45%|████▌     | 177/391 [00:27<00:29,  7.32it/s, processed=22656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  45%|████▌     | 177/391 [00:27<00:29,  7.32it/s, processed=22784/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  46%|████▌     | 178/391 [00:27<00:29,  7.29it/s, processed=22784/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  46%|████▌     | 178/391 [00:28<00:29,  7.29it/s, processed=22912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  46%|████▌     | 179/391 [00:28<00:29,  7.07it/s, processed=22912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  46%|████▌     | 179/391 [00:28<00:29,  7.07it/s, processed=23040/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  46%|████▌     | 180/391 [00:28<00:29,  7.13it/s, processed=23040/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  46%|████▌     | 180/391 [00:28<00:29,  7.13it/s, processed=23168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  46%|████▋     | 181/391 [00:28<00:29,  7.16it/s, processed=23168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  46%|████▋     | 181/391 [00:28<00:29,  7.16it/s, processed=23296/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  47%|████▋     | 182/391 [00:28<00:29,  7.19it/s, processed=23296/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  47%|████▋     | 182/391 [00:28<00:29,  7.19it/s, processed=23424/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  47%|████▋     | 183/391 [00:28<00:28,  7.41it/s, processed=23424/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  47%|████▋     | 183/391 [00:28<00:28,  7.41it/s, processed=23552/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  47%|████▋     | 184/391 [00:28<00:28,  7.32it/s, processed=23552/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  47%|████▋     | 184/391 [00:29<00:28,  7.32it/s, processed=23680/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  47%|████▋     | 185/391 [00:29<00:32,  6.25it/s, processed=23680/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  47%|████▋     | 185/391 [00:29<00:32,  6.25it/s, processed=23808/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  48%|████▊     | 186/391 [00:29<00:34,  5.92it/s, processed=23808/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  48%|████▊     | 186/391 [00:29<00:34,  5.92it/s, processed=23936/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  48%|████▊     | 187/391 [00:29<00:37,  5.45it/s, processed=23936/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  48%|████▊     | 187/391 [00:29<00:37,  5.45it/s, processed=24064/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  48%|████▊     | 188/391 [00:29<00:37,  5.35it/s, processed=24064/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  48%|████▊     | 188/391 [00:29<00:37,  5.35it/s, processed=24192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  48%|████▊     | 189/391 [00:29<00:38,  5.23it/s, processed=24192/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  48%|████▊     | 189/391 [00:30<00:38,  5.23it/s, processed=24320/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  49%|████▊     | 190/391 [00:30<00:38,  5.20it/s, processed=24320/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  49%|████▊     | 190/391 [00:30<00:38,  5.20it/s, processed=24448/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  49%|████▉     | 191/391 [00:30<00:35,  5.56it/s, processed=24448/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  49%|████▉     | 191/391 [00:30<00:35,  5.56it/s, processed=24576/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  49%|████▉     | 192/391 [00:30<00:32,  6.11it/s, processed=24576/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  49%|████▉     | 192/391 [00:30<00:32,  6.11it/s, processed=24704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  49%|████▉     | 193/391 [00:30<00:30,  6.55it/s, processed=24704/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  49%|████▉     | 193/391 [00:30<00:30,  6.55it/s, processed=24832/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  50%|████▉     | 194/391 [00:30<00:29,  6.72it/s, processed=24832/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  50%|████▉     | 194/391 [00:30<00:29,  6.72it/s, processed=24960/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  50%|████▉     | 195/391 [00:30<00:28,  6.80it/s, processed=24960/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  50%|████▉     | 195/391 [00:30<00:28,  6.80it/s, processed=25088/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  50%|█████     | 196/391 [00:30<00:28,  6.86it/s, processed=25088/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  50%|█████     | 196/391 [00:31<00:28,  6.86it/s, processed=25216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  50%|█████     | 197/391 [00:31<00:28,  6.82it/s, processed=25216/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  50%|█████     | 197/391 [00:31<00:28,  6.82it/s, processed=25344/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  51%|█████     | 198/391 [00:31<00:27,  7.01it/s, processed=25344/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  51%|█████     | 198/391 [00:31<00:27,  7.01it/s, processed=25472/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  51%|█████     | 199/391 [00:31<00:26,  7.13it/s, processed=25472/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  51%|█████     | 199/391 [00:31<00:26,  7.13it/s, processed=25600/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  51%|█████     | 200/391 [00:31<00:26,  7.17it/s, processed=25600/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  51%|█████     | 200/391 [00:31<00:26,  7.17it/s, processed=25728/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  51%|█████▏    | 201/391 [00:31<00:26,  7.15it/s, processed=25728/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  51%|█████▏    | 201/391 [00:31<00:26,  7.15it/s, processed=25856/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  52%|█████▏    | 202/391 [00:31<00:26,  7.10it/s, processed=25856/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  52%|█████▏    | 202/391 [00:31<00:26,  7.10it/s, processed=25984/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  52%|█████▏    | 203/391 [00:31<00:27,  6.94it/s, processed=25984/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  52%|█████▏    | 203/391 [00:32<00:27,  6.94it/s, processed=26112/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  52%|█████▏    | 204/391 [00:32<00:28,  6.54it/s, processed=26112/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  52%|█████▏    | 204/391 [00:32<00:28,  6.54it/s, processed=26240/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  52%|█████▏    | 205/391 [00:32<00:27,  6.67it/s, processed=26240/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  52%|█████▏    | 205/391 [00:32<00:27,  6.67it/s, processed=26368/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  53%|█████▎    | 206/391 [00:32<00:26,  6.86it/s, processed=26368/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  53%|█████▎    | 206/391 [00:32<00:26,  6.86it/s, processed=26496/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  53%|█████▎    | 207/391 [00:32<00:26,  6.88it/s, processed=26496/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  53%|█████▎    | 207/391 [00:32<00:26,  6.88it/s, processed=26624/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  53%|█████▎    | 208/391 [00:32<00:28,  6.37it/s, processed=26624/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  53%|█████▎    | 208/391 [00:32<00:28,  6.37it/s, processed=26752/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  53%|█████▎    | 209/391 [00:32<00:28,  6.29it/s, processed=26752/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  53%|█████▎    | 209/391 [00:32<00:28,  6.29it/s, processed=26880/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  54%|█████▎    | 210/391 [00:32<00:27,  6.51it/s, processed=26880/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  54%|█████▎    | 210/391 [00:33<00:27,  6.51it/s, processed=27008/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  54%|█████▍    | 211/391 [00:33<00:28,  6.30it/s, processed=27008/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  54%|█████▍    | 211/391 [00:33<00:28,  6.30it/s, processed=27136/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  54%|█████▍    | 212/391 [00:33<00:30,  5.94it/s, processed=27136/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  54%|█████▍    | 212/391 [00:33<00:30,  5.94it/s, processed=27264/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  54%|█████▍    | 213/391 [00:33<00:31,  5.68it/s, processed=27264/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  54%|█████▍    | 213/391 [00:33<00:31,  5.68it/s, processed=27392/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  55%|█████▍    | 214/391 [00:33<00:32,  5.51it/s, processed=27392/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  55%|█████▍    | 214/391 [00:33<00:32,  5.51it/s, processed=27520/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  55%|█████▍    | 215/391 [00:33<00:31,  5.67it/s, processed=27520/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  55%|█████▍    | 215/391 [00:33<00:31,  5.67it/s, processed=27648/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  55%|█████▌    | 216/391 [00:33<00:28,  6.06it/s, processed=27648/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  55%|█████▌    | 216/391 [00:34<00:28,  6.06it/s, processed=27776/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  55%|█████▌    | 217/391 [00:34<00:27,  6.32it/s, processed=27776/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  55%|█████▌    | 217/391 [00:34<00:27,  6.32it/s, processed=27904/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  56%|█████▌    | 218/391 [00:34<00:25,  6.66it/s, processed=27904/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  56%|█████▌    | 218/391 [00:34<00:25,  6.66it/s, processed=28032/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  56%|█████▌    | 219/391 [00:34<00:24,  6.95it/s, processed=28032/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  56%|█████▌    | 219/391 [00:34<00:24,  6.95it/s, processed=28160/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  56%|█████▋    | 220/391 [00:34<00:24,  7.03it/s, processed=28160/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  56%|█████▋    | 220/391 [00:34<00:24,  7.03it/s, processed=28288/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  57%|█████▋    | 221/391 [00:34<00:23,  7.10it/s, processed=28288/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  57%|█████▋    | 221/391 [00:34<00:23,  7.10it/s, processed=28416/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  57%|█████▋    | 222/391 [00:34<00:23,  7.08it/s, processed=28416/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  57%|█████▋    | 222/391 [00:34<00:23,  7.08it/s, processed=28544/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  57%|█████▋    | 223/391 [00:34<00:24,  6.98it/s, processed=28544/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  57%|█████▋    | 223/391 [00:35<00:24,  6.98it/s, processed=28672/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  57%|█████▋    | 224/391 [00:35<00:25,  6.46it/s, processed=28672/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  57%|█████▋    | 224/391 [00:35<00:25,  6.46it/s, processed=28800/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  58%|█████▊    | 225/391 [00:35<00:24,  6.73it/s, processed=28800/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  58%|█████▊    | 225/391 [00:35<00:24,  6.73it/s, processed=28928/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  58%|█████▊    | 226/391 [00:35<00:24,  6.79it/s, processed=28928/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  58%|█████▊    | 226/391 [00:35<00:24,  6.79it/s, processed=29056/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  58%|█████▊    | 227/391 [00:35<00:24,  6.81it/s, processed=29056/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  58%|█████▊    | 227/391 [00:35<00:24,  6.81it/s, processed=29184/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  58%|█████▊    | 228/391 [00:35<00:24,  6.68it/s, processed=29184/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  58%|█████▊    | 228/391 [00:35<00:24,  6.68it/s, processed=29312/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  59%|█████▊    | 229/391 [00:35<00:24,  6.57it/s, processed=29312/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  59%|█████▊    | 229/391 [00:36<00:24,  6.57it/s, processed=29440/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  59%|█████▉    | 230/391 [00:36<00:26,  6.13it/s, processed=29440/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  59%|█████▉    | 230/391 [00:36<00:26,  6.13it/s, processed=29568/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  59%|█████▉    | 231/391 [00:36<00:27,  5.81it/s, processed=29568/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  59%|█████▉    | 231/391 [00:36<00:27,  5.81it/s, processed=29696/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  59%|█████▉    | 232/391 [00:36<00:26,  6.01it/s, processed=29696/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  59%|█████▉    | 232/391 [00:36<00:26,  6.01it/s, processed=29824/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  60%|█████▉    | 233/391 [00:36<00:25,  6.20it/s, processed=29824/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  60%|█████▉    | 233/391 [00:36<00:25,  6.20it/s, processed=29952/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  60%|█████▉    | 234/391 [00:36<00:24,  6.44it/s, processed=29952/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  60%|█████▉    | 234/391 [00:36<00:24,  6.44it/s, processed=30080/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  60%|██████    | 235/391 [00:36<00:23,  6.52it/s, processed=30080/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  60%|██████    | 235/391 [00:37<00:23,  6.52it/s, processed=30208/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  60%|██████    | 236/391 [00:37<00:25,  6.09it/s, processed=30208/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  60%|██████    | 236/391 [00:37<00:25,  6.09it/s, processed=30336/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  61%|██████    | 237/391 [00:37<00:26,  5.75it/s, processed=30336/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  61%|██████    | 237/391 [00:37<00:26,  5.75it/s, processed=30464/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  61%|██████    | 238/391 [00:37<00:27,  5.47it/s, processed=30464/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  61%|██████    | 238/391 [00:37<00:27,  5.47it/s, processed=30592/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  61%|██████    | 239/391 [00:37<00:26,  5.66it/s, processed=30592/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  61%|██████    | 239/391 [00:37<00:26,  5.66it/s, processed=30720/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  61%|██████▏   | 240/391 [00:37<00:26,  5.68it/s, processed=30720/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  61%|██████▏   | 240/391 [00:37<00:26,  5.68it/s, processed=30848/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  62%|██████▏   | 241/391 [00:37<00:26,  5.56it/s, processed=30848/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  62%|██████▏   | 241/391 [00:38<00:26,  5.56it/s, processed=30976/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  62%|██████▏   | 242/391 [00:38<00:26,  5.69it/s, processed=30976/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  62%|██████▏   | 242/391 [00:38<00:26,  5.69it/s, processed=31104/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  62%|██████▏   | 243/391 [00:38<00:24,  5.92it/s, processed=31104/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  62%|██████▏   | 243/391 [00:38<00:24,  5.92it/s, processed=31232/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  62%|██████▏   | 244/391 [00:38<00:23,  6.14it/s, processed=31232/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  62%|██████▏   | 244/391 [00:38<00:23,  6.14it/s, processed=31360/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  63%|██████▎   | 245/391 [00:38<00:22,  6.36it/s, processed=31360/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  63%|██████▎   | 245/391 [00:38<00:22,  6.36it/s, processed=31488/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  63%|██████▎   | 246/391 [00:38<00:22,  6.46it/s, processed=31488/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  63%|██████▎   | 246/391 [00:38<00:22,  6.46it/s, processed=31616/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  63%|██████▎   | 247/391 [00:38<00:21,  6.55it/s, processed=31616/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  63%|██████▎   | 247/391 [00:39<00:21,  6.55it/s, processed=31744/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  63%|██████▎   | 248/391 [00:39<00:21,  6.79it/s, processed=31744/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  63%|██████▎   | 248/391 [00:39<00:21,  6.79it/s, processed=31872/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  64%|██████▎   | 249/391 [00:39<00:20,  6.90it/s, processed=31872/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  64%|██████▎   | 249/391 [00:39<00:20,  6.90it/s, processed=32000/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  64%|██████▍   | 250/391 [00:39<00:20,  6.83it/s, processed=32000/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  64%|██████▍   | 250/391 [00:39<00:20,  6.83it/s, processed=32128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  64%|██████▍   | 251/391 [00:39<00:20,  6.77it/s, processed=32128/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  64%|██████▍   | 251/391 [00:39<00:20,  6.77it/s, processed=32256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  64%|██████▍   | 252/391 [00:39<00:21,  6.51it/s, processed=32256/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  64%|██████▍   | 252/391 [00:39<00:21,  6.51it/s, processed=32384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  65%|██████▍   | 253/391 [00:39<00:23,  5.97it/s, processed=32384/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  65%|██████▍   | 253/391 [00:39<00:23,  5.97it/s, processed=32512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  65%|██████▍   | 254/391 [00:39<00:21,  6.38it/s, processed=32512/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  65%|██████▍   | 254/391 [00:40<00:21,  6.38it/s, processed=32640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  65%|██████▌   | 255/391 [00:40<00:21,  6.37it/s, processed=32640/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  65%|██████▌   | 255/391 [00:40<00:21,  6.37it/s, processed=32768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  65%|██████▌   | 256/391 [00:40<00:20,  6.51it/s, processed=32768/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  65%|██████▌   | 256/391 [00:40<00:20,  6.51it/s, processed=32896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  66%|██████▌   | 257/391 [00:40<00:20,  6.54it/s, processed=32896/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  66%|██████▌   | 257/391 [00:40<00:20,  6.54it/s, processed=33024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  66%|██████▌   | 258/391 [00:40<00:20,  6.46it/s, processed=33024/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  66%|██████▌   | 258/391 [00:40<00:20,  6.46it/s, processed=33152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  66%|██████▌   | 259/391 [00:40<00:22,  5.94it/s, processed=33152/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  66%|██████▌   | 259/391 [00:40<00:22,  5.94it/s, processed=33280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  66%|██████▋   | 260/391 [00:40<00:23,  5.65it/s, processed=33280/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  66%|██████▋   | 260/391 [00:41<00:23,  5.65it/s, processed=33408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  67%|██████▋   | 261/391 [00:41<00:23,  5.46it/s, processed=33408/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  67%|██████▋   | 261/391 [00:41<00:23,  5.46it/s, processed=33536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  67%|██████▋   | 262/391 [00:41<00:23,  5.44it/s, processed=33536/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  67%|██████▋   | 262/391 [00:41<00:23,  5.44it/s, processed=33664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  67%|██████▋   | 263/391 [00:41<00:22,  5.76it/s, processed=33664/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  67%|██████▋   | 263/391 [00:41<00:22,  5.76it/s, processed=33792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  68%|██████▊   | 264/391 [00:41<00:20,  6.10it/s, processed=33792/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  68%|██████▊   | 264/391 [00:41<00:20,  6.10it/s, processed=33920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  68%|██████▊   | 265/391 [00:41<00:19,  6.37it/s, processed=33920/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  68%|██████▊   | 265/391 [00:41<00:19,  6.37it/s, processed=34048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  68%|██████▊   | 266/391 [00:41<00:19,  6.47it/s, processed=34048/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  68%|██████▊   | 266/391 [00:42<00:19,  6.47it/s, processed=34176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  68%|██████▊   | 267/391 [00:42<00:20,  6.11it/s, processed=34176/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  68%|██████▊   | 267/391 [00:42<00:20,  6.11it/s, processed=34304/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  69%|██████▊   | 268/391 [00:42<00:20,  6.13it/s, processed=34304/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  69%|██████▊   | 268/391 [00:42<00:20,  6.13it/s, processed=34432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  69%|██████▉   | 269/391 [00:42<00:19,  6.19it/s, processed=34432/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  69%|██████▉   | 269/391 [00:42<00:19,  6.19it/s, processed=34560/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  69%|██████▉   | 270/391 [00:42<00:18,  6.41it/s, processed=34560/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  69%|██████▉   | 270/391 [00:42<00:18,  6.41it/s, processed=34688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  69%|██████▉   | 271/391 [00:42<00:19,  6.15it/s, processed=34688/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  69%|██████▉   | 271/391 [00:42<00:19,  6.15it/s, processed=34816/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  70%|██████▉   | 272/391 [00:42<00:19,  6.08it/s, processed=34816/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  70%|██████▉   | 272/391 [00:43<00:19,  6.08it/s, processed=34944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  70%|██████▉   | 273/391 [00:43<00:18,  6.36it/s, processed=34944/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  70%|██████▉   | 273/391 [00:43<00:18,  6.36it/s, processed=35072/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  70%|███████   | 274/391 [00:43<00:18,  6.28it/s, processed=35072/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  70%|███████   | 274/391 [00:43<00:18,  6.28it/s, processed=35200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  70%|███████   | 275/391 [00:43<00:19,  5.83it/s, processed=35200/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  70%|███████   | 275/391 [00:43<00:19,  5.83it/s, processed=35328/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  71%|███████   | 276/391 [00:43<00:18,  6.07it/s, processed=35328/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  71%|███████   | 276/391 [00:43<00:18,  6.07it/s, processed=35456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  71%|███████   | 277/391 [00:43<00:19,  5.93it/s, processed=35456/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  71%|███████   | 277/391 [00:43<00:19,  5.93it/s, processed=35584/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  71%|███████   | 278/391 [00:43<00:19,  5.95it/s, processed=35584/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  71%|███████   | 278/391 [00:44<00:19,  5.95it/s, processed=35712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  71%|███████▏  | 279/391 [00:44<00:17,  6.28it/s, processed=35712/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  71%|███████▏  | 279/391 [00:44<00:17,  6.28it/s, processed=35840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  72%|███████▏  | 280/391 [00:44<00:17,  6.27it/s, processed=35840/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  72%|███████▏  | 280/391 [00:44<00:17,  6.27it/s, processed=35968/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  72%|███████▏  | 281/391 [00:44<00:17,  6.45it/s, processed=35968/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  72%|███████▏  | 281/391 [00:44<00:17,  6.45it/s, processed=36096/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  72%|███████▏  | 282/391 [00:44<00:18,  5.87it/s, processed=36096/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  72%|███████▏  | 282/391 [00:44<00:18,  5.87it/s, processed=36224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  72%|███████▏  | 283/391 [00:44<00:19,  5.57it/s, processed=36224/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  72%|███████▏  | 283/391 [00:44<00:19,  5.57it/s, processed=36352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  73%|███████▎  | 284/391 [00:44<00:19,  5.50it/s, processed=36352/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  73%|███████▎  | 284/391 [00:45<00:19,  5.50it/s, processed=36480/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  73%|███████▎  | 285/391 [00:45<00:17,  5.89it/s, processed=36480/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  73%|███████▎  | 285/391 [00:45<00:17,  5.89it/s, processed=36608/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  73%|███████▎  | 286/391 [00:45<00:17,  6.17it/s, processed=36608/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  73%|███████▎  | 286/391 [00:45<00:17,  6.17it/s, processed=36736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  73%|███████▎  | 287/391 [00:45<00:16,  6.40it/s, processed=36736/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  73%|███████▎  | 287/391 [00:45<00:16,  6.40it/s, processed=36864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  74%|███████▎  | 288/391 [00:45<00:15,  6.49it/s, processed=36864/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  74%|███████▎  | 288/391 [00:45<00:15,  6.49it/s, processed=36992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  74%|███████▍  | 289/391 [00:45<00:15,  6.53it/s, processed=36992/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  74%|███████▍  | 289/391 [00:45<00:15,  6.53it/s, processed=37120/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  74%|███████▍  | 290/391 [00:45<00:15,  6.64it/s, processed=37120/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  74%|███████▍  | 290/391 [00:45<00:15,  6.64it/s, processed=37248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  74%|███████▍  | 291/391 [00:45<00:14,  6.72it/s, processed=37248/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  74%|███████▍  | 291/391 [00:46<00:14,  6.72it/s, processed=37376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  75%|███████▍  | 292/391 [00:46<00:14,  6.84it/s, processed=37376/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  75%|███████▍  | 292/391 [00:46<00:14,  6.84it/s, processed=37504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  75%|███████▍  | 293/391 [00:46<00:14,  6.84it/s, processed=37504/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  75%|███████▍  | 293/391 [00:46<00:14,  6.84it/s, processed=37632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  75%|███████▌  | 294/391 [00:46<00:14,  6.89it/s, processed=37632/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  75%|███████▌  | 294/391 [00:46<00:14,  6.89it/s, processed=37760/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  75%|███████▌  | 295/391 [00:46<00:14,  6.78it/s, processed=37760/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  75%|███████▌  | 295/391 [00:46<00:14,  6.78it/s, processed=37888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  76%|███████▌  | 296/391 [00:46<00:13,  6.80it/s, processed=37888/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  76%|███████▌  | 296/391 [00:46<00:13,  6.80it/s, processed=38016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  76%|███████▌  | 297/391 [00:46<00:14,  6.45it/s, processed=38016/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  76%|███████▌  | 297/391 [00:47<00:14,  6.45it/s, processed=38144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  76%|███████▌  | 298/391 [00:47<00:14,  6.46it/s, processed=38144/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  76%|███████▌  | 298/391 [00:47<00:14,  6.46it/s, processed=38272/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  76%|███████▋  | 299/391 [00:47<00:14,  6.27it/s, processed=38272/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  76%|███████▋  | 299/391 [00:47<00:14,  6.27it/s, processed=38400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  77%|███████▋  | 300/391 [00:47<00:14,  6.43it/s, processed=38400/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  77%|███████▋  | 300/391 [00:47<00:14,  6.43it/s, processed=38528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  77%|███████▋  | 301/391 [00:47<00:14,  6.26it/s, processed=38528/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  77%|███████▋  | 301/391 [00:47<00:14,  6.26it/s, processed=38656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  77%|███████▋  | 302/391 [00:47<00:13,  6.36it/s, processed=38656/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  77%|███████▋  | 302/391 [00:47<00:13,  6.36it/s, processed=38784/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  77%|███████▋  | 303/391 [00:47<00:13,  6.54it/s, processed=38784/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  77%|███████▋  | 303/391 [00:47<00:13,  6.54it/s, processed=38912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  78%|███████▊  | 304/391 [00:47<00:13,  6.58it/s, processed=38912/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  78%|███████▊  | 304/391 [00:48<00:13,  6.58it/s, processed=39040/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  78%|███████▊  | 305/391 [00:48<00:14,  5.97it/s, processed=39040/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  78%|███████▊  | 305/391 [00:48<00:14,  5.97it/s, processed=39168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  78%|███████▊  | 306/391 [00:48<00:15,  5.64it/s, processed=39168/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  78%|███████▊  | 306/391 [00:48<00:15,  5.64it/s, processed=39296/50000]\u001b[A\u001b[A\n",
      "\n",
      "Computing diversity scores:  79%|███████▊  | 307/391 [00:48<00:15,  5.38it/s, processed=39296/50000]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b395a8-e7c0-4ebc-9ba3-56aeb49c83b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
